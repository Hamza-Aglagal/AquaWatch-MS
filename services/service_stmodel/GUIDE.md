# ğŸ§  GUIDE SIMPLIFIÃ‰ STModel - PrÃ©diction QualitÃ© de l'Eau

**Service** : STModel (Spatio-Temporal Model)  
**DÃ©veloppeur** : Hamza  
**Technologies** : Python, PyTorch, ConvLSTM, FastAPI

---

## ğŸ“‹ TABLE DES MATIÃˆRES

1. [Votre Mission](#votre-mission)
2. [StratÃ©gie en 2 Phases](#stratÃ©gie-en-2-phases)
3. [Ã‰tapes RecommandÃ©es - Phase 1](#Ã©tapes-recommandÃ©es---phase-1)
4. [Transition vers Phase 2](#transition-vers-phase-2)

---

## ğŸ¯ VOTRE MISSION

CrÃ©er un **modÃ¨le d'intelligence artificielle** qui prÃ©dit la qualitÃ© de l'eau dans le **temps** (24h Ã  l'avance) et l'**espace** (diffÃ©rentes zones gÃ©ographiques).

**Exemple concret** : 
- PrÃ©dire qu'il y aura une augmentation de turbiditÃ© demain aprÃ¨s une pluie
- Identifier les zones Ã  risque de pollution

---

## ğŸš€ STRATÃ‰GIE EN 2 PHASES

### **PHASE 1 : DÃ©veloppement IndÃ©pendant (MAINTENANT - 2 semaines)**

**Objectif** : CrÃ©er et tester votre modÃ¨le sans attendre Bilal

âœ… **Avantages** :
- Vous travaillez de faÃ§on autonome
- Vous validez que votre modÃ¨le fonctionne
- API complÃ¨te et testÃ©e

ğŸ“Š **Source de donnÃ©es** : Dataset rÃ©el tÃ©lÃ©chargÃ© depuis Internet (Kaggle)

---

### **PHASE 2 : IntÃ©gration avec APIs (PLUS TARD - 2 jours)**

**Objectif** : Connecter votre modÃ¨le aux services de Bilal

âœ… **Avantages** :
- DonnÃ©es en temps rÃ©el
- IntÃ©gration complÃ¨te microservices
- PrÃ©dictions sur vraies donnÃ©es capteurs

ğŸ“¡ **Source de donnÃ©es** : APIs de Bilal (Capteurs IoT + Satellites)

---

## ğŸ¯ Ã‰TAPES RECOMMANDÃ‰ES - PHASE 1

### **Ã‰TAPE 1 : TÃ©lÃ©charger Datasets (1-2 heures)**

#### **Pourquoi deux datasets ?**
Pour entraÃ®ner un modÃ¨le complet, vous avez besoin de :
- **DonnÃ©es capteurs** : Mesures au sol prÃ©cises (pH, tempÃ©rature, turbiditÃ©, oxygÃ¨ne)
- **DonnÃ©es satellites** : Vision globale (chlorophylle, NDWI, turbiditÃ© optique)

**Ces deux sources sont complÃ©mentaires** et permettent au modÃ¨le d'apprendre des patterns spatio-temporels riches.

---

#### **ğŸ“Š A. DATASET CAPTEURS - Kaggle Water Quality**

**Lien** : https://www.kaggle.com/datasets/mssmartypants/water-quality

**Pourquoi ce dataset ?**
- âœ… **DonnÃ©es rÃ©elles** de capteurs de qualitÃ© de l'eau
- âœ… **Multiples paramÃ¨tres** : pH, turbiditÃ©, tempÃ©rature, oxygÃ¨ne, conductivitÃ©
- âœ… **SÃ©ries temporelles** : Mesures dans le temps
- âœ… **Localisations GPS** : CoordonnÃ©es des stations
- âœ… **Format CSV** : Facile Ã  manipuler avec Python
- âœ… **Gratuit** avec compte Kaggle

**Contenu typique** :
```csv
date,                latitude, longitude, station_id,  ph,  temperature, turbidity, dissolved_oxygen, conductivity
2024-01-01 08:00:00, 33.5731,  -7.5898,   STATION_001, 7.2, 22.5,        12.3,      8.1,              450
2024-01-01 09:00:00, 33.5731,  -7.5898,   STATION_001, 7.3, 22.8,        11.9,      8.0,              455
2024-01-01 10:00:00, 33.5731,  -7.5898,   STATION_001, 7.5, 23.1,        13.2,      7.9,              460
...
```

**ReprÃ©sente** : Service Capteurs de Bilal (mesures IoT au sol)

---

#### **ğŸ“¥ Comment tÃ©lÃ©charger le dataset Capteurs ?**

**Outil nÃ©cessaire** : **Kaggle CLI** (Command Line Interface)

**Pourquoi Kaggle CLI ?**
- TÃ©lÃ©chargement automatique des datasets
- Pas besoin de tÃ©lÃ©charger manuellement via navigateur
- Scriptable et reproductible

**Ã‰tapes** :

1. **CrÃ©er compte Kaggle** (gratuit)
   - Aller sur kaggle.com
   - S'inscrire avec email

2. **GÃ©nÃ©rer token API**
   - Aller dans Settings â†’ API â†’ "Create New Token"
   - Un fichier `kaggle.json` se tÃ©lÃ©charge
   - **RÃ´le** : Authentification pour tÃ©lÃ©charger datasets

3. **Installer Kaggle CLI**
   ```powershell
   pip install kaggle
   ```
   - **Outil** : Package Python pour interagir avec Kaggle
   - **Pourquoi** : Automatiser tÃ©lÃ©chargements

4. **Placer le token**
   - CrÃ©er dossier : `C:\Users\Hamza\.kaggle\`
   - Y mettre `kaggle.json`
   - **RÃ´le** : Stockage sÃ©curisÃ© des credentials

5. **TÃ©lÃ©charger dataset**
   ```powershell
   cd services/service_stmodel
   kaggle datasets download -d mssmartypants/water-quality -p data/raw/capteurs --unzip
   ```
   - **Explication** :
     - `kaggle datasets download` : Commande de tÃ©lÃ©chargement
     - `-d mssmartypants/water-quality` : ID du dataset
     - `-p data/raw/capteurs` : Destination (dossier capteurs)
     - `--unzip` : DÃ©compresser automatiquement

**RÃ©sultat** : Fichier CSV dans `data/raw/capteurs/water_quality.csv`

---

#### **ï¿½ï¸ B. DATASET SATELLITES - Sentinel Hub**

**Lien** : https://www.sentinel-hub.com/

**Pourquoi Sentinel Hub ?**
- âœ… **DonnÃ©es satellites Sentinel-2** (ESA - gratuit)
- âœ… **Indices prÃ©-calculÃ©s** : Chlorophylle, NDWI, turbiditÃ©
- âœ… **API facile** : TÃ©lÃ©chargement automatisÃ©
- âœ… **RÃ©solution spatiale** : 10-20m par pixel
- âœ… **FrÃ©quence** : Passage tous les 5 jours

**Produits disponibles** :
- **Chlorophylle-a** : Concentration d'algues (mg/mÂ³)
- **NDWI** (Normalized Difference Water Index) : DÃ©tection eau (0-1)
- **TurbiditÃ© optique** : Transparence vue du ciel (FNU)
- **TempÃ©rature de surface** : IR thermique (Â°C)

**Contenu typique** :
```csv
date,                latitude, longitude, chlorophyll, ndwi, turbidity_optical, temperature_surface
2024-01-01 10:30:00, 33.57,    -7.59,     0.8,         0.45, 15.2,             23.1
2024-01-06 10:30:00, 33.57,    -7.59,     0.85,        0.43, 14.8,             23.4
2024-01-11 10:30:00, 33.57,    -7.59,     0.92,        0.41, 16.1,             23.8
...
```

**ReprÃ©sente** : Service Satellite de Bilal (indices calculÃ©s depuis images satellites)

---

#### **ğŸ“¥ Comment tÃ©lÃ©charger le dataset Satellites ?**

**Option 1 : Sentinel Hub API (RecommandÃ©)**

**Ã‰tape 1 : CrÃ©er compte Sentinel Hub**
- Aller sur : https://www.sentinel-hub.com/
- S'inscrire (gratuit, trial 30 jours avec crÃ©dits)
- CrÃ©er un "Configuration" â†’ Noter OAuth Client ID et Secret

**Ã‰tape 2 : Installer sentinelhub-py**
```powershell
pip install sentinelhub
```

**Ã‰tape 3 : Configurer authentification**
```powershell
sentinelhub.config --sh_client_id <YOUR_CLIENT_ID> --sh_client_secret <YOUR_CLIENT_SECRET>
```

**Ã‰tape 4 : Script de tÃ©lÃ©chargement**

CrÃ©er `scripts/download_satellite_data.py` :

```python
from sentinelhub import SHConfig, BBox, CRS, DataCollection, SentinelHubRequest, bbox_to_dimensions, MimeType
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# Configuration
config = SHConfig()
# Vos credentials dÃ©jÃ  configurÃ©s

# Zone Ã  tÃ©lÃ©charger (correspondant aux capteurs)
# Exemple : Casablanca
bbox = BBox(bbox=[-7.8, 33.4, -7.4, 33.7], crs=CRS.WGS84)
size = bbox_to_dimensions(bbox, resolution=60)  # 60m rÃ©solution

# PÃ©riode (mÃªme que dataset capteurs)
start_date = datetime(2024, 1, 1)
end_date = datetime(2024, 12, 31)

# RequÃªte Sentinel Hub pour indices
evalscript = """
//VERSION=3
function setup() {
  return {
    input: ["B03", "B04", "B08", "B11"],
    output: { bands: 3 }
  };
}

function evaluatePixel(sample) {
  // NDWI (Normalized Difference Water Index)
  let ndwi = (sample.B03 - sample.B08) / (sample.B03 + sample.B08);
  
  // Chlorophyll estimation (algorithme simplifiÃ©)
  let chlorophyll = (sample.B04 / sample.B03) * 10;
  
  // Turbidity (algorithme simplifiÃ©)
  let turbidity = sample.B04 * 100;
  
  return [ndwi, chlorophyll, turbidity];
}
"""

request = SentinelHubRequest(
    evalscript=evalscript,
    input_data=[
        SentinelHubRequest.input_data(
            data_collection=DataCollection.SENTINEL2_L2A,
            time_interval=(start_date, end_date),
        )
    ],
    responses=[
        SentinelHubRequest.output_response('default', MimeType.TIFF)
    ],
    bbox=bbox,
    size=size,
    config=config
)

# TÃ©lÃ©charger
data = request.get_data()

# Sauvegarder
print(f"âœ… {len(data)} images tÃ©lÃ©chargÃ©es")
```

**Lancer** :
```powershell
python scripts/download_satellite_data.py
```

---

**Option 2 : Copernicus Open Access Hub (Gratuit, plus manuel)**

**Lien** : https://scihub.copernicus.eu/

**Ã‰tapes** :
1. CrÃ©er compte (gratuit)
2. Rechercher images Sentinel-2 pour vos zones/dates
3. TÃ©lÃ©charger produits L2A (rÃ©flectance de surface)
4. Traiter avec GDAL/rasterio pour extraire indices

**Note** : Plus complexe, requiert traitement d'images

---

**Option 3 : Dataset prÃ©-traitÃ© (Plus simple pour dÃ©buter)**

**Kaggle - Satellite Water Quality Indices**

Chercher sur Kaggle : "sentinel water quality indices" ou "chlorophyll satellite"

**Exemple** : 
- https://www.kaggle.com/datasets/franciscoescobar/satellite-images-of-water-bodies

**Avantage** : Indices dÃ©jÃ  calculÃ©s, format CSV prÃªt Ã  l'emploi

---

#### **ğŸ”— Ã‰TAPE 1.5 : Fusionner Capteurs + Satellites (1-2 heures)**

**Objectif** : CrÃ©er un dataset unique avec toutes les features (capteurs + satellites)

**ProblÃ¨me Ã  rÃ©soudre** :
- Capteurs : Mesures toutes les heures, positions GPS prÃ©cises
- Satellites : Passage tous les 5-10 jours, rÃ©solution spatiale 10-60m
- **Il faut aligner les donnÃ©es par temps et espace**

---

#### **ï¿½ Ã‰tapes de Fusion**

**CrÃ©er `scripts/merge_datasets.py`** :

```python
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

print("ğŸ”„ Fusion des datasets capteurs + satellites...\n")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. CHARGER LES DATASETS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Dataset Capteurs
df_capteurs = pd.read_csv('data/raw/capteurs/water_quality.csv')
print(f"ğŸ“Š Capteurs chargÃ©s : {len(df_capteurs)} lignes")
print(f"Colonnes : {df_capteurs.columns.tolist()}\n")

# Dataset Satellites
df_satellites = pd.read_csv('data/raw/satellites/sentinel_indices.csv')
print(f"ğŸ›°ï¸ Satellites chargÃ©s : {len(df_satellites)} lignes")
print(f"Colonnes : {df_satellites.columns.tolist()}\n")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. STANDARDISER LES COLONNES
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Renommer pour cohÃ©rence
df_capteurs = df_capteurs.rename(columns={
    'date': 'timestamp',
    'dissolved_oxygen': 'oxygene_dissous',
    'turbidity': 'turbidite_capteur'
})

df_satellites = df_satellites.rename(columns={
    'date': 'timestamp',
    'turbidity_optical': 'turbidite_satellite',
    'chlorophyll': 'chlorophylle',
    'temperature_surface': 'temperature_surface'
})

# Convertir timestamps en datetime
df_capteurs['timestamp'] = pd.to_datetime(df_capteurs['timestamp'])
df_satellites['timestamp'] = pd.to_datetime(df_satellites['timestamp'])

print("âœ… Colonnes standardisÃ©es\n")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. ARRONDIR LES COORDONNÃ‰ES GPS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ProblÃ¨me : Satellites ont rÃ©solution spatiale 10-60m
# Solution : Arrondir GPS Ã  2-3 dÃ©cimales

df_capteurs['lat_round'] = df_capteurs['latitude'].round(2)  # ~1km prÃ©cision
df_capteurs['lon_round'] = df_capteurs['longitude'].round(2)

df_satellites['lat_round'] = df_satellites['latitude'].round(2)
df_satellites['lon_round'] = df_satellites['longitude'].round(2)

print("âœ… CoordonnÃ©es GPS arrondies\n")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. ALIGNER TEMPORELLEMENT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ProblÃ¨me : Satellites passent tous les 5-10 jours
# Solution : Forward fill (propager derniÃ¨re valeur satellite)

# CrÃ©er une grille temporelle complÃ¨te (toutes les heures)
date_range = pd.date_range(
    start=df_capteurs['timestamp'].min(),
    end=df_capteurs['timestamp'].max(),
    freq='H'  # Heure par heure
)

# RÃ©indexer satellites sur cette grille
df_satellites_aligned = df_satellites.set_index('timestamp')
df_satellites_aligned = df_satellites_aligned.reindex(date_range)

# Forward fill : Propager derniÃ¨re valeur satellite disponible
df_satellites_aligned = df_satellites_aligned.fillna(method='ffill')
df_satellites_aligned = df_satellites_aligned.reset_index()
df_satellites_aligned = df_satellites_aligned.rename(columns={'index': 'timestamp'})

print("âœ… Alignement temporel effectuÃ©\n")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. FUSIONNER PAR TIMESTAMP + GPS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

df_combined = pd.merge(
    df_capteurs,
    df_satellites_aligned[['timestamp', 'lat_round', 'lon_round', 
                          'chlorophylle', 'ndwi', 'turbidite_satellite', 
                          'temperature_surface']],
    on=['timestamp', 'lat_round', 'lon_round'],
    how='left'  # Garder toutes les lignes capteurs
)

print(f"âœ… Fusion effectuÃ©e : {len(df_combined)} lignes\n")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. GÃ‰RER VALEURS MANQUANTES
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Certaines zones peuvent ne pas avoir de donnÃ©es satellite
# Remplir avec valeurs moyennes ou interpolation

print("ğŸ” Valeurs manquantes avant traitement :")
print(df_combined[['chlorophylle', 'ndwi', 'turbidite_satellite']].isnull().sum())
print()

# Interpolation linÃ©aire pour valeurs manquantes
df_combined['chlorophylle'] = df_combined['chlorophylle'].interpolate(method='linear')
df_combined['ndwi'] = df_combined['ndwi'].interpolate(method='linear')
df_combined['turbidite_satellite'] = df_combined['turbidite_satellite'].interpolate(method='linear')
df_combined['temperature_surface'] = df_combined['temperature_surface'].interpolate(method='linear')

# Remplir valeurs encore manquantes avec moyenne
df_combined = df_combined.fillna(df_combined.mean(numeric_only=True))

print("âœ… Valeurs manquantes traitÃ©es\n")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7. SÃ‰LECTIONNER FEATURES FINALES
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Colonnes Ã  garder (format API Bilal)
features_finales = [
    # MÃ©tadonnÃ©es
    'timestamp',
    'latitude',
    'longitude',
    'station_id',
    
    # Capteurs (comme API Bilal - Service Capteurs)
    'ph',
    'temperature',
    'turbidite_capteur',
    'oxygene_dissous',
    'conductivity',
    
    # Satellites (comme API Bilal - Service Satellite)
    'chlorophylle',
    'ndwi',
    'turbidite_satellite',
    'temperature_surface'
]

df_final = df_combined[features_finales]

print("ğŸ“‹ Features finales sÃ©lectionnÃ©es :")
print(df_final.columns.tolist())
print()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 8. CALCULER SCORE DE QUALITÃ‰ (TARGET)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def calculer_qualite(row):
    """
    Calcule score de qualitÃ© (0-10) basÃ© sur normes OMS
    """
    score = 10  # Parfait au dÃ©part
    
    # pH doit Ãªtre entre 6.5 et 8.5
    if row['ph'] < 6.5 or row['ph'] > 8.5:
        score -= 3
    
    # TempÃ©rature < 25Â°C
    if row['temperature'] > 25:
        score -= 2
    
    # TurbiditÃ© < 5 NTU
    if row['turbidite_capteur'] > 5:
        score -= 2
    
    # OxygÃ¨ne > 6 mg/L
    if row['oxygene_dissous'] < 6:
        score -= 3
    
    # Chlorophylle < 2 mg/mÂ³ (risque algues)
    if row['chlorophylle'] > 2:
        score -= 2
    
    # NDWI > 0.3 (eau claire)
    if row['ndwi'] < 0.3:
        score -= 1
    
    return max(0, min(10, score))  # Entre 0 et 10

# Appliquer le calcul
df_final['qualite_score'] = df_final.apply(calculer_qualite, axis=1)

print("âœ… Score de qualitÃ© calculÃ©\n")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 9. STATISTIQUES FINALES
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

print("ğŸ“Š STATISTIQUES DATASET FINAL")
print("=" * 60)
print(f"Nombre total d'Ã©chantillons : {len(df_final)}")
print(f"PÃ©riode : {df_final['timestamp'].min()} â†’ {df_final['timestamp'].max()}")
print(f"Nombre de stations : {df_final['station_id'].nunique()}")
print()

print("Distribution qualitÃ© :")
print(df_final['qualite_score'].value_counts(bins=5).sort_index())
print()

print("AperÃ§u des donnÃ©es :")
print(df_final.head(3))
print()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 10. SAUVEGARDER DATASET FINAL
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

output_path = 'data/processed/water_quality_combined.csv'
df_final.to_csv(output_path, index=False)

print(f"âœ… Dataset final sauvegardÃ© : {output_path}")
print(f"ğŸ“ Taille : {len(df_final)} lignes Ã— {len(df_final.columns)} colonnes")
print()

print("ğŸ‰ Fusion terminÃ©e avec succÃ¨s !")
print()
print("ğŸ“‹ Format compatible avec APIs Bilal :")
print("  - Capteurs : ph, temperature, turbidite, oxygene_dissous")
print("  - Satellites : chlorophylle, ndwi, turbidite_satellite, temperature_surface")
```

**Lancer la fusion** :
```powershell
python scripts/merge_datasets.py
```

---

#### **âœ… RÃ©sultat de la Fusion**

**Fichier final** : `data/processed/water_quality_combined.csv`

**Structure (compatible APIs Bilal)** :
```csv
timestamp,           latitude, longitude, station_id,  ph,  temperature, turbidite_capteur, oxygene_dissous, conductivity, chlorophylle, ndwi, turbidite_satellite, temperature_surface, qualite_score
2024-01-01 08:00:00, 33.5731,  -7.5898,   STATION_001, 7.2, 22.5,        12.3,              8.1,             450,          0.8,          0.45, 15.2,                23.1,                6
2024-01-01 09:00:00, 33.5731,  -7.5898,   STATION_001, 7.3, 22.8,        11.9,              8.0,             455,          0.8,          0.45, 15.2,                23.1,                6
...
```

**Features (13 au total)** :
- **Capteurs (7)** : timestamp, lat, lon, pH, temp, turbiditÃ©, O2, conductivitÃ©
- **Satellites (4)** : chlorophylle, NDWI, turbiditÃ© optique, temp surface
- **Target (1)** : qualite_score (0-10)
- **MÃ©tadonnÃ©es (1)** : station_id

---

#### **ğŸ” VÃ©rification de la Fusion**

**CrÃ©er `notebooks/01_verify_fusion.ipynb`** :

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Charger dataset fusionnÃ©
df = pd.read_csv('../data/processed/water_quality_combined.csv')

# VÃ©rifications
print("âœ… VÃ‰RIFICATIONS")
print("=" * 60)
print(f"Nombre d'Ã©chantillons : {len(df)}")
print(f"Features : {df.columns.tolist()}")
print(f"Valeurs manquantes : {df.isnull().sum().sum()}")
print()

# CorrÃ©lations capteurs vs satellites
print("ğŸ“Š CORRÃ‰LATIONS CAPTEURS â†” SATELLITES")
print("=" * 60)
print(f"TurbiditÃ© capteur vs satellite : {df['turbidite_capteur'].corr(df['turbidite_satellite']):.3f}")
print(f"TempÃ©rature eau vs surface : {df['temperature'].corr(df['temperature_surface']):.3f}")
print()

# Visualisation
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# CorrÃ©lation turbiditÃ©s
axes[0,0].scatter(df['turbidite_capteur'], df['turbidite_satellite'], alpha=0.5)
axes[0,0].set_xlabel('TurbiditÃ© Capteur (NTU)')
axes[0,0].set_ylabel('TurbiditÃ© Satellite (FNU)')
axes[0,0].set_title('Validation : TurbiditÃ©s Capteur vs Satellite')

# CorrÃ©lation tempÃ©ratures
axes[0,1].scatter(df['temperature'], df['temperature_surface'], alpha=0.5)
axes[0,1].set_xlabel('TempÃ©rature Eau (Â°C)')
axes[0,1].set_ylabel('TempÃ©rature Surface (Â°C)')
axes[0,1].set_title('Validation : TempÃ©ratures Eau vs Surface')

# Distribution qualitÃ©
df['qualite_score'].hist(bins=20, ax=axes[1,0])
axes[1,0].set_xlabel('Score QualitÃ©')
axes[1,0].set_ylabel('FrÃ©quence')
axes[1,0].set_title('Distribution Score QualitÃ©')

# Heatmap corrÃ©lations
corr = df[['ph', 'temperature', 'turbidite_capteur', 'oxygene_dissous', 
           'chlorophylle', 'ndwi', 'qualite_score']].corr()
sns.heatmap(corr, annot=True, fmt='.2f', ax=axes[1,1], cmap='coolwarm')
axes[1,1].set_title('Matrice CorrÃ©lations')

plt.tight_layout()
plt.savefig('../data/processed/fusion_validation.png', dpi=300)
print("âœ… Graphiques sauvegardÃ©s : fusion_validation.png")
```

---

### **Ã‰TAPE 2 : Explorer et Comprendre les DonnÃ©es (1-2 heures)**

#### **Pourquoi explorer ?**
Avant d'entraÃ®ner un modÃ¨le, vous devez **comprendre vos donnÃ©es** :
- Quelles sont les valeurs typiques ?
- Y a-t-il des valeurs manquantes ?
- Comment les paramÃ¨tres Ã©voluent dans le temps ?
- Y a-t-il des corrÃ©lations entre paramÃ¨tres ?

---

#### **ğŸ”§ Outil : Jupyter Notebook**

**C'est quoi ?**
- **Interface interactive** pour analyser des donnÃ©es
- MÃ©lange de code Python et visualisations
- Permet d'exÃ©cuter du code cellule par cellule
- IdÃ©al pour exploration et tests

**Pourquoi Jupyter ?**
- Visualisation instantanÃ©e des rÃ©sultats
- Graphiques intÃ©grÃ©s
- Documentation au fil de l'eau
- Standard en Data Science

**Installation** :
```powershell
pip install jupyter notebook pandas matplotlib seaborn
```

---

#### **ğŸ“Š Analyses Ã  faire**

**1. Chargement et Inspection**
- **Outil** : `pandas` (bibliothÃ¨que Python pour manipuler tableaux)
- **Pourquoi pandas** : Lit CSV, manipule colonnes, calcule statistiques
- **Actions** :
  - Charger le CSV
  - Voir les premiÃ¨res lignes (`head()`)
  - Comprendre la structure (colonnes, types de donnÃ©es)
  - Compter le nombre de lignes (Ã©chantillons)

**2. Statistiques Descriptives**
- **Outil** : `pandas.describe()`
- **Pourquoi** : Obtenir min, max, moyenne, Ã©cart-type de chaque paramÃ¨tre
- **UtilitÃ©** : DÃ©tecter valeurs aberrantes (ex: pH = 15 â†’ impossible)

**3. Valeurs Manquantes**
- **Outil** : `pandas.isnull().sum()`
- **Pourquoi** : Certains capteurs peuvent avoir des pannes
- **ProblÃ¨me** : ModÃ¨les ML ne gÃ¨rent pas les trous de donnÃ©es
- **Solution** : Remplissage (imputation) ou suppression

**4. Distributions**
- **Outil** : `matplotlib` ou `seaborn` (visualisations graphiques)
- **Pourquoi** : Voir comment les valeurs sont rÃ©parties
- **Types de graphiques** :
  - **Histogramme** : Distribution d'un paramÃ¨tre
  - **Boxplot** : Identifier outliers (valeurs extrÃªmes)
  - **Exemple** : Si pH est toujours entre 7-8 â†’ normal

**5. CorrÃ©lations**
- **Outil** : `pandas.corr()` + Heatmap (carte de chaleur)
- **Pourquoi** : Voir si des paramÃ¨tres sont liÃ©s
- **Exemple** :
  - TempÃ©rature â†‘ â†’ OxygÃ¨ne â†“ (corrÃ©lation nÃ©gative)
  - TurbiditÃ© â†‘ â†’ Chlorophylle â†‘ (corrÃ©lation positive)
- **UtilitÃ©** : Comprendre les relations pour le modÃ¨le

**6. Ã‰volution Temporelle**
- **Outil** : Graphiques de sÃ©ries temporelles (lignes)
- **Pourquoi** : Voir les tendances dans le temps
- **Patterns Ã  chercher** :
  - **SaisonnalitÃ©** : TempÃ©rature haute en Ã©tÃ©
  - **Tendances** : Pollution qui augmente progressivement
  - **Pics** : TurbiditÃ© aprÃ¨s pluie
- **UtilitÃ©** : Le modÃ¨le doit apprendre ces patterns

---

### **Ã‰TAPE 3 : PrÃ©paration des DonnÃ©es (2-3 heures)**

#### **Pourquoi prÃ©parer ?**
Les modÃ¨les de Machine Learning ont besoin de donnÃ©es **propres** et **formatÃ©es** correctement. C'est l'Ã©tape la plus importante (80% du travail en ML) !

---

#### **ğŸ§¹ Nettoyage des DonnÃ©es**

**1. GÃ©rer les Valeurs Manquantes**

**ProblÃ¨me** : Capteur en panne â†’ pas de mesure
**Exemple** : pH manquant Ã  14h00

**Solutions** :

- **Suppression** :
  - **Quand** : Peu de valeurs manquantes (< 5%)
  - **Comment** : Supprimer les lignes incomplÃ¨tes
  - **Outil** : `pandas.dropna()`
  - **InconvÃ©nient** : Perte d'informations

- **Imputation (Remplissage)** :
  - **MÃ©thode 1 - Moyenne** : Remplacer par valeur moyenne
    - **Outil** : `pandas.fillna(df.mean())`
    - **Quand** : DonnÃ©es stables
  
  - **MÃ©thode 2 - Forward Fill** : RÃ©pÃ©ter derniÃ¨re valeur connue
    - **Outil** : `pandas.fillna(method='ffill')`
    - **Quand** : Valeurs qui changent lentement
    - **Exemple** : pH Ã  14h manquant â†’ utiliser pH de 13h
  
  - **MÃ©thode 3 - Interpolation** : Calculer valeur entre deux points
    - **Outil** : `pandas.interpolate()`
    - **Quand** : SÃ©ries temporelles continues
    - **Exemple** : pH = 7.0 Ã  13h, pH = 7.4 Ã  15h â†’ pH 14h â‰ˆ 7.2

**2. Supprimer les Outliers (Valeurs Aberrantes)**

**ProblÃ¨me** : Erreurs de capteur â†’ valeurs impossibles
**Exemple** : pH = 25 (impossible, max thÃ©orique = 14)

**MÃ©thodes** :

- **RÃ¨gles mÃ©tier** :
  - pH doit Ãªtre entre 0 et 14
  - TempÃ©rature entre -5Â°C et 40Â°C
  - Supprimer tout ce qui sort des limites

- **MÃ©thode statistique (Z-score)** :
  - **Principe** : Si valeur > 3 Ã©carts-types â†’ outlier
  - **Outil** : `scipy.stats.zscore`
  - **Exemple** : Si pH moyen = 7.5 et toutes les valeurs entre 7-8, une valeur Ã  12 est suspecte

---

#### **ğŸ“ Normalisation des DonnÃ©es**

**ProblÃ¨me** : Les paramÃ¨tres ont des Ã©chelles diffÃ©rentes
- pH : 0-14
- TempÃ©rature : 0-40Â°C
- ConductivitÃ© : 0-2000 Î¼S/cm

**Pourquoi normaliser ?**
- Les rÃ©seaux de neurones fonctionnent mieux avec valeurs entre 0 et 1
- Ã‰vite qu'un paramÃ¨tre "domine" les autres
- AccÃ©lÃ¨re l'apprentissage

**MÃ©thode : Min-Max Scaling**
- **Formule** : `(valeur - min) / (max - min)`
- **RÃ©sultat** : Toutes les valeurs entre 0 et 1
- **Outil** : `scikit-learn.MinMaxScaler`
- **Exemple** :
  - TempÃ©rature originale : 20Â°C (min=0, max=40)
  - NormalisÃ©e : (20-0)/(40-0) = 0.5

**MÃ©thode Alternative : Standardisation**
- **Formule** : `(valeur - moyenne) / Ã©cart-type`
- **RÃ©sultat** : Moyenne = 0, Ã©cart-type = 1
- **Outil** : `scikit-learn.StandardScaler`
- **Quand l'utiliser** : Quand distribution gaussienne (cloche)

---

#### **ğŸ”¢ CrÃ©er des SÃ©quences Temporelles**

**Pourquoi ?**
Votre modÃ¨le doit **apprendre des patterns temporels**. Il faut lui montrer une **fenÃªtre de temps passÃ©** pour prÃ©dire le futur.

**Concept : Sliding Window (FenÃªtre Glissante)**

**Exemple concret** :
- Vous voulez prÃ©dire la qualitÃ© Ã  24h
- Vous utilisez les 24 derniÃ¨res heures comme input

```
Input (X) : 24 mesures passÃ©es (heures 0 Ã  23)
Output (y) : QualitÃ© Ã  l'heure 24
```

**ParamÃ¨tres importants** :

1. **Sequence Length (Longueur de sÃ©quence)** :
   - **C'est quoi** : Nombre de pas de temps passÃ©s Ã  utiliser
   - **Exemple** : `sequence_length = 24` â†’ utiliser 24 heures passÃ©es
   - **Choix** : 
     - 24 heures â†’ prÃ©diction court terme
     - 72 heures (3 jours) â†’ prÃ©diction moyen terme
   - **RÃ¨gle** : Plus long = plus de contexte, mais plus complexe

2. **Horizon (Horizon de prÃ©diction)** :
   - **C'est quoi** : Combien de temps dans le futur prÃ©dire
   - **Exemple** : `horizon = 24` â†’ prÃ©dire dans 24h
   - **Choix selon besoin** :
     - 6h â†’ trÃ¨s court terme
     - 24h â†’ court terme (recommandÃ©)
     - 72h â†’ moyen terme

**Construction des sÃ©quences** :

**Outil** : `numpy` (bibliothÃ¨que calcul matriciel)

**MÃ©canisme** :
```
DonnÃ©es brutes : [mesure1, mesure2, mesure3, ..., mesure100]

SÃ©quence 1 :
  Input  : mesures 1-24
  Output : qualitÃ© heure 25

SÃ©quence 2 :
  Input  : mesures 2-25
  Output : qualitÃ© heure 26

SÃ©quence 3 :
  Input  : mesures 3-26
  Output : qualitÃ© heure 27

... etc
```

**RÃ©sultat** : 
- X : Tableau 3D (nombre_sÃ©quences, 24, nombre_features)
- y : Tableau 1D (nombre_sÃ©quences,) avec scores de qualitÃ©

---

#### **ğŸ—ºï¸ CrÃ©er une Grille Spatiale (AvancÃ©)**

**Pourquoi ?**
Le **ConvLSTM** combine :
- **LSTM** : Apprend le temps
- **CNN** : Apprend l'espace (comme les images)

Pour utiliser CNN, besoin d'une **grille 2D** (comme une image).

**Concept** :
- Transformer points GPS dispersÃ©s en grille rÃ©guliÃ¨re
- Chaque cellule = zone gÃ©ographique

**Exemple** :
```
Zone : Casablanca (33.4-33.7 N, -7.8 Ã  -7.4 W)
Grille : 10x10 cellules
Chaque cellule : 3km x 3km
```

**MÃ©thode : Interpolation Spatiale**
- **ProblÃ¨me** : Capteur seulement Ã  certains points
- **Solution** : Estimer valeurs entre les points
- **Outil** : `scipy.interpolate.griddata`
- **Techniques** :
  - **Nearest** : Prendre valeur du capteur le plus proche
  - **Linear** : Interpolation linÃ©aire entre capteurs
  - **Cubic** : Interpolation lisse (courbe)

**RÃ©sultat** :
- X : Tableau 5D (sÃ©quences, temps, features, hauteur_grille, largeur_grille)
- **Exemple** : (1000, 24, 7, 10, 10)

**Note** : Pour dÃ©buter, vous pouvez **skip cette partie** et utiliser un LSTM simple (sans grille spatiale).

---

### **Ã‰TAPE 4 : Construire le ModÃ¨le ConvLSTM (3-4 heures)**

#### **ğŸ§  Comprendre ConvLSTM**

**C'est quoi ?**
Un rÃ©seau de neurones qui combine :
- **LSTM** (Long Short-Term Memory) : MÃ©moire temporelle
- **Convolutions** (CNN) : Vision spatiale

---

#### **ğŸ“š Les Composants**

**1. LSTM (MÃ©moire Temporelle)**

**ProblÃ¨me rÃ©solu** : 
- Les rÃ©seaux classiques "oublient" le passÃ©
- LSTM se souvient des informations importantes

**Comment Ã§a marche** :
- **Cell State** : MÃ©moire Ã  long terme
- **Hidden State** : MÃ©moire Ã  court terme
- **Gates (Portes)** : ContrÃ´lent ce qu'on garde/oublie
  - **Forget Gate** : DÃ©cide quoi oublier
  - **Input Gate** : DÃ©cide quoi mÃ©moriser
  - **Output Gate** : DÃ©cide quoi sortir

**Exemple** :
```
Heure 1 : pH = 7.0 â†’ LSTM mÃ©morise
Heure 2 : pH = 7.1 â†’ LSTM compare avec heure 1
Heure 3 : pH = 7.5 â†’ LSTM dÃ©tecte augmentation
PrÃ©diction : Tendance Ã  la hausse
```

**Pourquoi LSTM pour qualitÃ© eau ?**
- QualitÃ© Ã©volue lentement dans le temps
- Ã‰vÃ©nements passÃ©s influencent le futur (ex: pluie â†’ turbiditÃ©)
- Besoin de mÃ©moire longue durÃ©e

---

**2. CNN (Vision Spatiale)**

**ProblÃ¨me rÃ©solu** :
- Capteurs voisins sont corrÃ©lÃ©s
- Pollution se propage dans l'espace

**Comment Ã§a marche** :
- **Convolution** : Filtre qui scanne la grille spatiale
- **Kernel** : Petite fenÃªtre (ex: 3x3) qui cherche des patterns
- DÃ©tecte patterns locaux (ex: zone polluÃ©e)

**Exemple** :
```
Station A : pH = 7.0
Station B (voisine) : pH = 6.8
Station C (voisine) : pH = 6.9
â†’ CNN dÃ©tecte : zone acidification
```

---

**3. ConvLSTM = LSTM + CNN**

**Principe** :
- Applique convolutions **dans le temps**
- Chaque pas de temps = image spatiale
- LSTM gÃ¨re l'Ã©volution temporelle de ces images

**Avantage** :
- Capture patterns spatio-temporels complexes
- Ex: Pollution qui se dÃ©place dans l'espace et Ã©volue dans le temps

---

#### **ğŸ—ï¸ Architecture du ModÃ¨le**

**Couches du modÃ¨le** :

**1. Couche Input**
- **RÃ´le** : Recevoir les donnÃ©es
- **Shape** : (batch, sequence, features, height, width)
- **Exemple** : (32, 24, 7, 10, 10)
  - 32 sÃ©quences Ã  la fois
  - 24 pas de temps
  - 7 features (pH, temp, etc.)
  - Grille 10x10

**2. Couches ConvLSTM (x2 ou x3)**
- **RÃ´le** : Apprendre patterns spatio-temporels
- **ParamÃ¨tres** :
  - **Hidden dim** : Nombre de filtres (ex: 64)
  - **Kernel size** : Taille fenÃªtre (ex: 3x3)
  - **Nombre de couches** : 2-3 couches empilÃ©es
- **Pourquoi plusieurs couches** :
  - Couche 1 : Patterns simples
  - Couche 2 : Patterns complexes
  - Couche 3 : Patterns trÃ¨s abstraits

**3. Pooling Layer**
- **RÃ´le** : RÃ©duire dimensions spatiales
- **Type** : AdaptiveAvgPool2d
- **Effet** : Grille 10x10 â†’ 1 valeur globale
- **Pourquoi** : RÃ©sumer l'information spatiale

**4. Fully Connected Layers (Dense)**
- **RÃ´le** : Transformer features en prÃ©diction finale
- **Architecture typique** :
  - Layer 1 : 64 â†’ 32 neurones
  - ReLU (activation)
  - Dropout (rÃ©gularisation, Ã©vite overfitting)
  - Layer 2 : 32 â†’ 1 neurone (score qualitÃ©)

**5. Output**
- **RÃ©sultat** : Score de qualitÃ© (0-10)

---

#### **ğŸ”§ Outils PyTorch**

**Pourquoi PyTorch ?**
- Framework ML flexible et puissant
- TrÃ¨s utilisÃ© en recherche
- Support GPU (calcul rapide)
- CommunautÃ© active

**Modules utilisÃ©s** :

- **torch.nn.Module** : Classe de base pour modÃ¨les
- **torch.nn.Conv2d** : Convolutions spatiales
- **torch.nn.LSTM** ou **ConvLSTMCell** : MÃ©moire temporelle
- **torch.nn.Linear** : Couches fully connected
- **torch.nn.ReLU** : Fonction d'activation
- **torch.nn.Dropout** : RÃ©gularisation
- **torch.optim** : Optimiseurs (Adam, SGD)
- **torch.nn.MSELoss** : Fonction de perte (Mean Squared Error)

---

#### **ğŸš€ Version SimplifiÃ©e : LSTM sans Convolutions**

**Recommandation** : Commencez par un **LSTM simple** sans grille spatiale !

**Pourquoi ?**
- Plus facile Ã  implÃ©menter
- Plus rapide Ã  entraÃ®ner
- Valide dÃ©jÃ  les prÃ©dictions temporelles
- Peut Ãªtre amÃ©liorÃ© plus tard

**Architecture simplifiÃ©e** :
```
Input (batch, 24, 7)  # 24 heures, 7 features
  â†“
LSTM Layer 1 (64 units)
  â†“
LSTM Layer 2 (64 units)
  â†“
Fully Connected (64 â†’ 32)
  â†“
ReLU + Dropout
  â†“
Fully Connected (32 â†’ 1)
  â†“
Output : Score qualitÃ©
```

**Quand passer Ã  ConvLSTM ?**
- Quand LSTM simple marche bien
- Quand vous avez donnÃ©es multi-stations
- Pour amÃ©liorer prÃ©cision spatiale

---

### **Ã‰TAPE 5 : EntraÃ®ner le ModÃ¨le (2-4 heures)**

#### **ğŸ¯ Comprendre l'EntraÃ®nement**

**C'est quoi l'entraÃ®nement ?**
Processus itÃ©ratif oÃ¹ le modÃ¨le **apprend** Ã  partir des donnÃ©es en ajustant ses paramÃ¨tres (poids).

**Analogie** : Comme apprendre Ã  faire du vÃ©lo
- Au dÃ©but : Beaucoup d'erreurs
- Avec pratique : De mieux en mieux
- Ã€ la fin : Automatique et prÃ©cis

---

#### **ğŸ“Š Split des DonnÃ©es**

**Pourquoi diviser ?**
Pour Ã©valuer si le modÃ¨le **gÃ©nÃ©ralise** (marche sur nouvelles donnÃ©es).

**3 Ensembles** :

**1. Train Set (70%)**
- **RÃ´le** : EntraÃ®ner le modÃ¨le
- **Usage** : Le modÃ¨le apprend sur ces donnÃ©es
- **Exemple** : 7000 Ã©chantillons sur 10000

**2. Validation Set (15%)**
- **RÃ´le** : Ajuster hyperparamÃ¨tres pendant entraÃ®nement
- **Usage** : VÃ©rifier performance sans "tricher"
- **Exemple** : 1500 Ã©chantillons
- **Pourquoi sÃ©parÃ©** : Ã‰viter l'overfitting (sur-apprentissage)

**3. Test Set (15%)**
- **RÃ´le** : Ã‰valuation finale
- **Usage** : Mesurer performance rÃ©elle
- **Exemple** : 1500 Ã©chantillons
- **RÃ¨gle** : Jamais utilisÃ© pendant entraÃ®nement !

**Outil** : `scikit-learn.train_test_split`

---

#### **ğŸ” Le Processus d'EntraÃ®nement**

**1. Epoch (Ã‰poque)**
- **C'est quoi** : Un passage complet sur toutes les donnÃ©es d'entraÃ®nement
- **Nombre typique** : 50-100 epochs
- **Pourquoi plusieurs** : Apprentissage progressif

**2. Batch (Lot)**
- **C'est quoi** : Groupe d'Ã©chantillons traitÃ©s ensemble
- **Taille typique** : 16, 32 ou 64
- **Pourquoi batches** : Optimise mÃ©moire GPU
- **Outil** : `torch.utils.data.DataLoader`

**3. Forward Pass (Passe avant)**
- **Ã‰tape** : DonnÃ©es â†’ ModÃ¨le â†’ PrÃ©diction
- **Exemple** : Input pH/temp â†’ ModÃ¨le â†’ PrÃ©diction qualitÃ© = 7.2

**4. Loss (Perte/Erreur)**
- **C'est quoi** : Mesure de l'erreur du modÃ¨le
- **Formule MSE** : `(prÃ©diction - vÃ©ritÃ©)Â²`
- **Exemple** :
  - PrÃ©diction : 7.2
  - VÃ©ritÃ© : 7.5
  - Loss : (7.2 - 7.5)Â² = 0.09
- **Objectif** : Minimiser la loss

**5. Backward Pass (RÃ©tropropagation)**
- **Ã‰tape** : Calculer gradients (dÃ©rivÃ©es)
- **RÃ´le** : Savoir comment ajuster poids
- **Outil** : `loss.backward()` (automatique PyTorch)

**6. Optimization (Optimisation)**
- **Ã‰tape** : Ajuster poids du modÃ¨le
- **Algorithme** : **Adam** (recommandÃ©)
- **ParamÃ¨tre clÃ©** : **Learning Rate** (taux d'apprentissage)
  - **C'est quoi** : Taille des pas d'ajustement
  - **Valeur typique** : 0.001 ou 0.0001
  - **Trop grand** : ModÃ¨le instable
  - **Trop petit** : Apprentissage trÃ¨s lent

---

#### **ğŸ“ˆ Monitoring de l'EntraÃ®nement**

**MÃ©triques Ã  surveiller** :

**1. Train Loss**
- **C'est quoi** : Erreur sur donnÃ©es d'entraÃ®nement
- **Ã‰volution** : Doit diminuer rÃ©guliÃ¨rement
- **ProblÃ¨me si** : Ne diminue pas â†’ learning rate trop faible ou modÃ¨le trop simple

**2. Validation Loss**
- **C'est quoi** : Erreur sur donnÃ©es de validation
- **Ã‰volution** : Doit suivre train loss
- **ProblÃ¨me si** : Augmente alors que train loss baisse â†’ **Overfitting**

**Overfitting (Sur-apprentissage)** :
- **ProblÃ¨me** : ModÃ¨le "apprend par cÅ“ur" au lieu de gÃ©nÃ©raliser
- **SymptÃ´me** : Train loss â†“, Val loss â†‘
- **Solutions** :
  - **Dropout** : DÃ©sactive alÃ©atoirement des neurones
  - **Early Stopping** : ArrÃªter avant overfitting
  - **RÃ©gularisation L2** : PÃ©naliser poids trop grands
  - **Plus de donnÃ©es** : Augmenter dataset

---

#### **ğŸ”§ Techniques AvancÃ©es**

**1. Learning Rate Scheduler**
- **RÃ´le** : RÃ©duire learning rate progressivement
- **StratÃ©gie** : `ReduceLROnPlateau`
  - Si validation loss stagne â†’ rÃ©duire LR
- **Pourquoi** : Affiner apprentissage en fin d'entraÃ®nement

**2. Early Stopping**
- **RÃ´le** : ArrÃªter si pas d'amÃ©lioration
- **ParamÃ¨tre** : Patience (ex: 10 epochs)
- **Exemple** : Si val loss ne s'amÃ©liore pas pendant 10 epochs â†’ stop

**3. Model Checkpointing**
- **RÃ´le** : Sauvegarder le meilleur modÃ¨le
- **CritÃ¨re** : Meilleure validation loss
- **Pourquoi** : Garder le modÃ¨le optimal (pas le dernier)

---

#### **ğŸ’¾ Sauvegarde du ModÃ¨le**

**Format PyTorch** : `.pth` file

**Contenu sauvegardÃ©** :
- **State dict** : Tous les poids du modÃ¨le
- **Optimizer state** : Ã‰tat de l'optimiseur (optionnel)
- **HyperparamÃ¨tres** : Architecture (pour charger plus tard)
- **Metrics** : Performances (MSE, MAE, etc.)

**Outil** : `torch.save()` et `torch.load()`

**MÃ©tadonnÃ©es Ã  sauvegarder** (fichier JSON sÃ©parÃ©) :
- Type de modÃ¨le
- HyperparamÃ¨tres (hidden_dim, num_layers, etc.)
- Performances (MSE, MAE, RÂ²)
- Date d'entraÃ®nement
- Nom du dataset
- Nombre d'Ã©chantillons

---

### **Ã‰TAPE 6 : CrÃ©er l'API REST avec FastAPI (2-3 heures)**

#### **ğŸŒ Comprendre les APIs REST**

**C'est quoi une API ?**
- **Application Programming Interface**
- Permet Ã  des programmes de communiquer
- Comme un restaurant : menu (API) â†’ commander (requÃªte) â†’ plat (rÃ©ponse)

**REST (Representational State Transfer)** :
- Style d'architecture API
- Utilise HTTP (protocole web)
- Format JSON pour Ã©changes
- Verbes : GET (lire), POST (crÃ©er), PUT (modifier), DELETE (supprimer)

---

#### **ğŸ”§ Pourquoi FastAPI ?**

**Avantages** :
- **Rapide** : Performance excellente
- **Modern** : Python 3.7+, async/await
- **Documentation auto** : GÃ©nÃ¨re interface interactive (Swagger)
- **Validation** : VÃ©rification automatique des donnÃ©es (Pydantic)
- **Type hints** : Code plus clair et sÃ»r

**Alternative** : Flask (plus ancien, moins features)

---

#### **ğŸ“¡ Endpoints Ã  CrÃ©er**

**1. GET /health**
- **RÃ´le** : VÃ©rifier que le service fonctionne
- **RÃ©ponse** :
  ```json
  {
    "status": "healthy",
    "service": "stmodel",
    "model_loaded": true
  }
  ```
- **Usage** : Monitoring, Docker healthcheck

**2. GET /api/model/info**
- **RÃ´le** : Informations sur le modÃ¨le actuel
- **RÃ©ponse** :
  ```json
  {
    "model_type": "SimpleWaterQualityLSTM",
    "hidden_dim": 64,
    "test_mse": 0.34,
    "trained_on": "2025-10-27"
  }
  ```
- **Usage** : Debugging, traÃ§abilitÃ©

**3. POST /api/predictions/create**
- **RÃ´le** : CrÃ©er une nouvelle prÃ©diction
- **Input** : 24 derniÃ¨res mesures
- **Output** : PrÃ©diction qualitÃ©
- **Exemple input** :
  ```json
  {
    "measurements": [
      {
        "latitude": 33.5731,
        "longitude": -7.5898,
        "ph": 7.2,
        "temperature": 22.5,
        "turbidite": 12.3,
        "oxygene_dissous": 8.1,
        "chlorophylle": 0.8
      },
      ... (24 mesures)
    ],
    "horizon": 24
  }
  ```
- **Exemple output** :
  ```json
  {
    "prediction_id": "PRED_20251027140530",
    "qualite_score": 7.2,
    "qualite_categorie": "BONNE",
    "confiance": 0.85,
    "horizon_heures": 24,
    "timestamp": "2025-10-27T14:05:30"
  }
  ```

**4. GET /api/predictions/latest**
- **RÃ´le** : RÃ©cupÃ©rer derniÃ¨res prÃ©dictions
- **Usage** : Dashboard, historique
- **Note** : Phase 1 = mock, Phase 2 = vraie DB

---

#### **ğŸ” Validation avec Pydantic**

**C'est quoi Pydantic ?**
- BibliothÃ¨que de validation de donnÃ©es
- DÃ©finit **schÃ©mas** (structures attendues)
- VÃ©rifie automatiquement les types
- GÃ©nÃ¨re erreurs claires si problÃ¨me

**Exemple : SchÃ©ma de Mesure**
```python
class WaterQualityMeasurement(BaseModel):
    latitude: float      # Doit Ãªtre un nombre dÃ©cimal
    longitude: float
    ph: float
    temperature: float
    ...
```

**Avantages** :
- Ã‰vite erreurs (ex: pH = "sept" â†’ refusÃ©)
- Documentation automatique
- Code plus sÃ»r

---

#### **âš¡ Chargement du ModÃ¨le au DÃ©marrage**

**ProblÃ¨me** : Charger le modÃ¨le est lent (plusieurs secondes)

**Solution** : Charger **une seule fois** au dÃ©marrage du service

**MÃ©canisme** :
- **Startup event** : `@app.on_event("startup")`
- FastAPI exÃ©cute au lancement
- ModÃ¨le chargÃ© en mÃ©moire
- PrÃªt pour toutes les requÃªtes suivantes

**Avantages** :
- RequÃªtes trÃ¨s rapides (<100ms)
- Pas de rechargement Ã  chaque appel

---

#### **ğŸ” Gestion des Erreurs**

**Types d'erreurs Ã  gÃ©rer** :

**1. Erreur 400 : Bad Request**
- **Cause** : DonnÃ©es input invalides
- **Exemple** : Seulement 10 mesures au lieu de 24
- **RÃ©ponse** :
  ```json
  {
    "detail": "24 mesures requises, 10 fournies"
  }
  ```

**2. Erreur 503 : Service Unavailable**
- **Cause** : ModÃ¨le non chargÃ©
- **Exemple** : Fichier .pth manquant
- **RÃ©ponse** :
  ```json
  {
    "detail": "ModÃ¨le non disponible"
  }
  ```

**3. Erreur 500 : Internal Server Error**
- **Cause** : Erreur inattendue
- **Exemple** : Bug dans le code
- **Action** : Logger l'erreur pour debugging

**Outil** : `FastAPI.HTTPException`

---

### **Ã‰TAPE 7 : Stockage en Base de DonnÃ©es (1-2 heures)**

#### **ğŸ—„ï¸ Pourquoi PostgreSQL ?**

**C'est quoi PostgreSQL ?**
- Base de donnÃ©es relationnelle (SQL)
- Open source et robuste
- TrÃ¨s utilisÃ© en production

**Avantages** :
- Stockage persistant (donnÃ©es sauvegardÃ©es)
- RequÃªtes complexes (SQL)
- Transactions (cohÃ©rence des donnÃ©es)
- PostGIS pour donnÃ©es gÃ©ographiques (bonus)

**Votre base dÃ©diÃ©e** : `predictions_db` (port 5434)

---

#### **ğŸ“‹ Tables Ã  CrÃ©er**

**1. Table `ml_models`**
- **RÃ´le** : Historique des modÃ¨les entraÃ®nÃ©s
- **Colonnes** :
  - `id` : Identifiant unique
  - `name` : Nom du modÃ¨le (ex: "water_quality_v1")
  - `version` : NumÃ©ro de version
  - `architecture` : Type (LSTM, ConvLSTM)
  - `hyperparameters` : JSON avec config
  - `metrics` : JSON avec performances
  - `trained_at` : Date entraÃ®nement
  - `model_path` : Chemin fichier .pth
  - `is_active` : BoolÃ©en (modÃ¨le en production)

**2. Table `predictions`**
- **RÃ´le** : Toutes les prÃ©dictions effectuÃ©es
- **Colonnes** :
  - `id` : Identifiant unique
  - `prediction_id` : ID lisible (ex: PRED_20251027...)
  - `model_id` : RÃ©fÃ©rence au modÃ¨le utilisÃ©
  - `latitude` : Position GPS
  - `longitude` : Position GPS
  - `qualite_score` : RÃ©sultat (0-10)
  - `qualite_categorie` : EXCELLENTE/BONNE/MOYENNE/MAUVAISE
  - `confiance` : Score de confiance (0-1)
  - `horizon_heures` : Horizon de prÃ©diction
  - `created_at` : Timestamp crÃ©ation
  - `input_data` : JSON avec donnÃ©es input (optionnel)

**3. Table `training_logs` (Optionnel)**
- **RÃ´le** : Historique d'entraÃ®nements
- **Colonnes** :
  - `id`
  - `model_id`
  - `epoch` : NumÃ©ro d'Ã©poque
  - `train_loss` : Loss train
  - `val_loss` : Loss validation
  - `timestamp`

---

#### **ğŸ”Œ Connexion Ã  la Base**

**Outil** : **SQLAlchemy** (ORM Python)

**C'est quoi un ORM ?**
- **Object-Relational Mapping**
- Manipuler base de donnÃ©es avec objets Python
- Pas besoin d'Ã©crire SQL manuellement
- Plus sÃ©curisÃ© (Ã©vite injections SQL)

**Alternative** : `psycopg2` (connexion directe, plus bas niveau)

**Connection String** :
```
postgresql://predictions_user:predictions_pass_2025@db_predictions:5432/predictions_db
```
- `predictions_user` : Utilisateur
- `predictions_pass_2025` : Mot de passe
- `db_predictions` : Nom du container Docker
- `5432` : Port PostgreSQL (interne Docker)
- `predictions_db` : Nom de la base

---

#### **ğŸ’¾ Sauvegarder une PrÃ©diction**

**Workflow** :
1. Recevoir requÃªte API
2. Faire prÃ©diction avec modÃ¨le
3. **InsÃ©rer en base de donnÃ©es**
4. Retourner rÃ©ponse API

**Avantages stockage** :
- Historique complet
- Analyses rÃ©trospectives
- TraÃ§abilitÃ©
- Dashboard avec statistiques

---

### **Ã‰TAPE 8 : Communication avec Yassin via Redis (1 heure)**

#### **ğŸ“¢ Pourquoi Redis ?**

**C'est quoi Redis ?**
- Base de donnÃ©es **en mÃ©moire** (trÃ¨s rapide)
- SystÃ¨me de **Pub/Sub** (Publication/Souscription)
- Comme une messagerie entre services

**Pub/Sub expliquÃ©** :
- **Publisher** (Vous) : Publie messages
- **Channel** : Canal de communication (ex: "new_prediction")
- **Subscriber** (Yassin) : Ã‰coute les messages

**Analogie** : Radio
- Vous = Station radio qui Ã©met
- Canal = FrÃ©quence (ex: 95.5 FM)
- Yassin = Auditeur qui Ã©coute cette frÃ©quence

---

#### **ğŸ”— Workflow avec Yassin**

**1. Vous crÃ©ez prÃ©diction** â†’ **2. Publiez sur Redis** â†’ **3. Yassin reÃ§oit** â†’ **4. CrÃ©e alerte si besoin**

**Exemple concret** :
```
Votre prÃ©diction : QualitÃ© = MAUVAISE, Score = 3.2
  â†“
Publiez sur canal "new_prediction"
  â†“
Yassin Ã©coute ce canal
  â†“
Yassin voit : QualitÃ© mauvaise !
  â†“
Yassin crÃ©e alerte email/SMS
```

---

#### **ğŸ“¨ Format du Message**

**Canal** : `"new_prediction"`

**Message (JSON)** :
```json
{
  "prediction_id": "PRED_20251027140530",
  "zone": {
    "latitude": 33.5731,
    "longitude": -7.5898
  },
  "predictions": {
    "qualite_eau": "MAUVAISE",
    "score_qualite": 3.2,
    "ph_predit": 8.7,
    "risque_pollution": "ELEVE"
  },
  "confiance": 0.85,
  "timestamp": "2025-10-27T14:05:30",
  "horizon_heures": 24
}
```

---

#### **ğŸ”§ Outil : redis-py**

**C'est quoi** : Client Redis pour Python

**Installation** : `pip install redis`

**Usage** :
```python
import redis

# Connexion
r = redis.Redis(host='redis_queue', port=6379)

# Publier
r.publish('new_prediction', message_json)
```

**Avantages** :
- Asynchrone (non-bloquant)
- TrÃ¨s rapide (millisecondes)
- DÃ©couplage entre services

---

## ğŸ”„ TRANSITION VERS PHASE 2

### **Quand Bilal a TerminÃ© ses Services**

#### **Ã‰tape 2.1 : VÃ©rifier APIs de Bilal (30 min)**

**Tests Ã  faire** :

**1. API Capteurs**
```powershell
curl http://localhost:8001/api/capteurs/data/latest?hours=24
```
**VÃ©rifier** :
- Retourne JSON avec liste de mesures
- Contient : pH, tempÃ©rature, turbiditÃ©, oxygÃ¨ne
- Au moins 24 mesures disponibles
- Timestamps corrects

**2. API Satellite**
```powershell
curl "http://localhost:8002/api/satellite/indices/latest?latitude=33.5731&longitude=-7.5898"
```
**VÃ©rifier** :
- Retourne indices calculÃ©s
- Contient : chlorophylle, turbiditÃ© satellite, tempÃ©rature surface
- DonnÃ©es rÃ©centes (< 1 semaine)

---

#### **Ã‰tape 2.2 : CrÃ©er Client API (1 heure)**

**RÃ´le** : Module Python pour appeler APIs de Bilal

**Fichier** : `src/data/api_client.py`

**FonctionnalitÃ©s** :

**1. RÃ©cupÃ©rer DonnÃ©es Capteurs**
- **MÃ©thode** : `get_capteurs_data(hours=24)`
- **Outil** : `requests` (HTTP client Python)
- **Gestion erreurs** :
  - Timeout (10 secondes)
  - Service indisponible â†’ fallback
  - Retry avec backoff exponentiel

**2. RÃ©cupÃ©rer DonnÃ©es Satellite**
- **MÃ©thode** : `get_satellite_data(lat, lon, radius_km=5)`
- **ParamÃ¨tre radius** : Zone autour du point
- **AgrÃ©gation** : Moyenne si plusieurs valeurs

**3. Fusionner DonnÃ©es**
- **MÃ©thode** : `combine_data(capteurs, satellite)`
- **Logique** :
  - Pour chaque mesure capteur
  - Ajouter indices satellite correspondants (mÃªme zone/temps)
  - CrÃ©er DataFrame complet
- **Outil** : `pandas` pour fusion

---

#### **Ã‰tape 2.3 : Adapter Service de PrÃ©diction (30 min)**

**Modification** : `src/services/prediction_service.py`

**Ajout : Mode API**

**Configuration** (fichier `.env`) :
```bash
# Phase 1
USE_API_DATA=false

# Phase 2 (activer quand prÃªt)
USE_API_DATA=true
```

**Logique conditionnelle** :
```python
if USE_API_DATA:
    # RÃ©cupÃ©rer donnÃ©es via APIs Bilal
    data = api_client.get_data()
else:
    # Utiliser dataset local (Phase 1)
    data = load_from_csv()
```

**Avantage** :
- Changement transparent
- Pas de rÃ©Ã©criture majeure
- Testable (switch on/off)

---

#### **Ã‰tape 2.4 : Tests d'IntÃ©gration (1 heure)**

**1. Test Unitaire**
- VÃ©rifier que client API fonctionne
- Mock (simuler) rÃ©ponses pour tests

**2. Test End-to-End**
- RequÃªte API â†’ Appel Bilal â†’ PrÃ©diction â†’ RÃ©ponse
- VÃ©rifier temps de rÃ©ponse (< 2 secondes)

**3. Test de Charge (Optionnel)**
- Outil : `locust` ou `ab` (Apache Bench)
- Simuler 100 requÃªtes/seconde
- VÃ©rifier stabilitÃ©

---

#### **Ã‰tape 2.5 : RÃ©-entraÃ®nement (Optionnel, 1 jour)**

**Pourquoi rÃ©-entraÃ®ner ?**
- Dataset initial â‰  vraies donnÃ©es terrain
- AmÃ©liorer prÃ©cision avec donnÃ©es rÃ©elles

**Processus** :

**1. Collecte DonnÃ©es RÃ©elles**
- Lancer APIs pendant 1-2 semaines
- Stocker toutes les mesures
- Constituer nouveau dataset

**2. Comparaison**
- Dataset Phase 1 vs DonnÃ©es rÃ©elles
- VÃ©rifier distributions similaires
- Identifier diffÃ©rences

**3. RÃ©-entraÃ®nement**
- MÃªme processus que Phase 1
- Utiliser nouveau dataset
- Comparer performances

**4. A/B Testing (AvancÃ©)**
- ModÃ¨le v1 (Phase 1) sur 50% trafic
- ModÃ¨le v2 (Phase 2) sur 50% trafic
- Comparer prÃ©cision
- Garder le meilleur

---

## âœ… RÃ‰CAPITULATIF DES Ã‰TAPES RECOMMANDÃ‰ES

### **PHASE 1 (2 semaines)**

| Ã‰tape | DurÃ©e | PrioritÃ© |
|-------|-------|----------|
| 1. TÃ©lÃ©charger dataset Kaggle | 30 min | â­â­â­ |
| 2. Explorer donnÃ©es (Jupyter) | 1-2h | â­â­â­ |
| 3. PrÃ©traitement (nettoyage + normalisation) | 2-3h | â­â­â­ |
| 4. ModÃ¨le LSTM simple | 3-4h | â­â­â­ |
| 5. EntraÃ®nement | 2-4h | â­â­â­ |
| 6. API FastAPI | 2-3h | â­â­â­ |
| 7. Stockage PostgreSQL | 1-2h | â­â­ |
| 8. Communication Redis | 1h | â­â­ |

**Total** : ~15-20 heures de travail

---

### **PHASE 2 (2 jours)**

| Ã‰tape | DurÃ©e | PrioritÃ© |
|-------|-------|----------|
| 1. Tester APIs Bilal | 30 min | â­â­â­ |
| 2. Client API | 1h | â­â­â­ |
| 3. Adapter service | 30 min | â­â­â­ |
| 4. Tests intÃ©gration | 1h | â­â­â­ |
| 5. RÃ©-entraÃ®nement (optionnel) | 1 jour | â­ |

---

## ğŸ¯ CONSEILS FINAUX

### **Pour DÃ©buter**

1. âœ… **Commencez simple** : LSTM avant ConvLSTM
2. âœ… **Testez souvent** : AprÃ¨s chaque Ã©tape
3. âœ… **Logs partout** : Pour comprendre ce qui se passe
4. âœ… **Git rÃ©guliÃ¨rement** : Commit aprÃ¨s chaque fonctionnalitÃ©
5. âœ… **Documentation** : Notez vos dÃ©cisions et rÃ©sultats

### **PrioritÃ©s**

**Semaine 1** :
- Dataset + Exploration + PrÃ©traitement
- ModÃ¨le LSTM simple qui tourne

**Semaine 2** :
- EntraÃ®nement + Optimisation
- API fonctionnelle
- IntÃ©gration DB et Redis

**AprÃ¨s** :
- AmÃ©liorer modÃ¨le (ConvLSTM)
- Optimiser performances
- Monitoring et logging

---

## ğŸ†˜ RÃ‰SOLUTION PROBLÃˆMES

### **Dataset ne tÃ©lÃ©charge pas**
- VÃ©rifier token Kaggle dans bon dossier
- VÃ©rifier connexion Internet
- Essayer tÃ©lÃ©chargement manuel

### **ModÃ¨le ne converge pas**
- RÃ©duire learning rate (0.001 â†’ 0.0001)
- VÃ©rifier normalisation des donnÃ©es
- Simplifier architecture (moins de couches)
- Augmenter nombre d'epochs

### **API ne rÃ©pond pas**
- VÃ©rifier modÃ¨le chargÃ© au startup
- VÃ©rifier logs Docker : `docker compose logs -f service_stmodel`
- Tester health endpoint d'abord

### **Erreur mÃ©moire (Out of Memory)**
- RÃ©duire batch size (32 â†’ 16)
- RÃ©duire taille modÃ¨le (hidden_dim: 64 â†’ 32)
- Utiliser CPU si GPU insuffisant

---

**ğŸš€ Bonne chance ! Vous avez tout pour rÃ©ussir ! ğŸŒŠ**

---

## ğŸ“ STRUCTURE DU PROJET

```
services/service_stmodel/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                      # Point d'entrÃ©e FastAPI
â”‚   â”œâ”€â”€ config.py                    # Configuration (DB, Redis, URLs)
â”‚   â”‚
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ connection.py            # Connexion PostgreSQL
â”‚   â”‚   â””â”€â”€ models.py                # Tables SQL (predictions, models)
â”‚   â”‚
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ convlstm.py              # Architecture ConvLSTM PyTorch
â”‚   â”‚   â”œâ”€â”€ train.py                 # Script entraÃ®nement
â”‚   â”‚   â”œâ”€â”€ predict.py               # Service de prÃ©diction
â”‚   â”‚   â””â”€â”€ preprocessing.py         # Nettoyage et normalisation
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_loader.py           # PHASE 1 : Charger dataset externe
â”‚   â”‚   â””â”€â”€ api_client.py            # PHASE 2 : Appeler APIs Bilal
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ prediction_service.py    # Logique prÃ©diction
â”‚   â”‚   â””â”€â”€ redis_publisher.py       # Publier vers Yassin
â”‚   â”‚
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ routes.py                # Endpoints REST
â”‚
â”œâ”€â”€ data/                            # Datasets pour Phase 1
â”‚   â”œâ”€â”€ raw/                         # DonnÃ©es brutes tÃ©lÃ©chargÃ©es
â”‚   â”œâ”€â”€ processed/                   # DonnÃ©es nettoyÃ©es
â”‚   â””â”€â”€ README.md                    # Documentation datasets
â”‚
â”œâ”€â”€ models/                          # ModÃ¨les entraÃ®nÃ©s
â”‚   â”œâ”€â”€ convlstm_v1.pth             # ModÃ¨le Phase 1
â”‚   â”œâ”€â”€ convlstm_v2.pth             # ModÃ¨le Phase 2 (avec APIs)
â”‚   â””â”€â”€ model_info.json             # MÃ©tadonnÃ©es (prÃ©cision, etc.)
â”‚
â”œâ”€â”€ notebooks/                       # Jupyter pour exploration
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb   # Analyser dataset
â”‚   â”œâ”€â”€ 02_model_training.ipynb     # EntraÃ®ner modÃ¨le
â”‚   â””â”€â”€ 03_evaluation.ipynb         # Tester performance
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_api.py                 # Tests API
â”‚   â”œâ”€â”€ test_model.py               # Tests modÃ¨le
â”‚   â””â”€â”€ test_data.py                # Tests chargement donnÃ©es
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_dataset.py         # TÃ©lÃ©charger donnÃ©es Kaggle
â”‚   â”œâ”€â”€ train_model.sh              # Lancer entraÃ®nement
â”‚   â””â”€â”€ test_api.sh                 # Tester endpoints
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ GUIDE.md                         # Ce fichier
```

---

## ğŸ”¥ PHASE 1 : ENTRAÃNEMENT AVEC DATASET EXTERNE

### **Ã‰tape 1.1 : TÃ©lÃ©charger un dataset (30 min)**

#### **Option A : Kaggle (RecommandÃ©)**

1. **Installer Kaggle CLI**
```powershell
pip install kaggle
```

2. **Configurer API Token**
   - Aller sur : https://www.kaggle.com/settings
   - CrÃ©er un token API â†’ TÃ©lÃ©charger `kaggle.json`
   - Placer dans : `C:\Users\Hamza\.kaggle\kaggle.json`

3. **TÃ©lÃ©charger dataset**
```powershell
cd services/service_stmodel
kaggle datasets download -d adityakadiwal/water-potability -p data/raw --unzip
```

#### **Option B : DonnÃ©es simulÃ©es (Plus rapide pour dÃ©buter)**

**CrÃ©er `scripts/generate_synthetic_data.py`**

```python
import numpy as np
import pandas as pd
from datetime import datetime, timedelta

def generate_water_quality_data(n_samples=10000):
    """
    GÃ©nÃ¨re des donnÃ©es synthÃ©tiques de qualitÃ© de l'eau
    avec patterns temporels et spatiaux
    """
    
    np.random.seed(42)
    
    # Timestamps (1 an de donnÃ©es, mesures toutes les heures)
    start_date = datetime(2024, 1, 1)
    timestamps = [start_date + timedelta(hours=i) for i in range(n_samples)]
    
    # Localisations (Casablanca rÃ©gion)
    latitudes = np.random.uniform(33.4, 33.7, n_samples)
    longitudes = np.random.uniform(-7.8, -7.4, n_samples)
    
    # ParamÃ¨tres avec patterns rÃ©alistes
    # pH : normale autour de 7.5, varie avec tempÃ©rature
    ph = np.random.normal(7.5, 0.5, n_samples)
    
    # TempÃ©rature : saisonnalitÃ©
    temps = np.arange(n_samples)
    temperature = 20 + 5 * np.sin(2 * np.pi * temps / (365*24)) + np.random.normal(0, 2, n_samples)
    
    # TurbiditÃ© : pics aprÃ¨s pluie (simulÃ©)
    turbidite = np.abs(np.random.gamma(2, 3, n_samples))
    
    # OxygÃ¨ne dissous : inversement corrÃ©lÃ© Ã  tempÃ©rature
    oxygene = 10 - 0.15 * temperature + np.random.normal(0, 0.5, n_samples)
    
    # Chlorophylle : corrÃ©lÃ©e Ã  tempÃ©rature (algues)
    chlorophylle = np.maximum(0, 0.2 * temperature - 2 + np.random.normal(0, 0.5, n_samples))
    
    # Score qualitÃ© (0-10, 10 = excellente)
    qualite = (
        0.3 * (10 - np.abs(ph - 7.5) * 4) +  # pH optimal = 7.5
        0.2 * (10 - turbidite / 5) +          # Moins de turbiditÃ© = mieux
        0.3 * (oxygene / 1.2) +               # Plus d'oxygÃ¨ne = mieux
        0.2 * (10 - chlorophylle)             # Moins de chlorophylle = mieux
    )
    qualite = np.clip(qualite, 0, 10)
    
    # CrÃ©er DataFrame
    df = pd.DataFrame({
        'timestamp': timestamps,
        'latitude': latitudes,
        'longitude': longitudes,
        'ph': ph,
        'temperature': temperature,
        'turbidite': turbidite,
        'oxygene_dissous': oxygene,
        'chlorophylle': chlorophylle,
        'qualite_score': qualite
    })
    
    return df

if __name__ == "__main__":
    print("ğŸŒŠ GÃ©nÃ©ration de donnÃ©es synthÃ©tiques...")
    df = generate_water_quality_data(10000)
    
    # Sauvegarder
    df.to_csv('data/raw/synthetic_water_quality.csv', index=False)
    print(f"âœ… {len(df)} Ã©chantillons gÃ©nÃ©rÃ©s dans data/raw/synthetic_water_quality.csv")
    print(f"\nğŸ“Š AperÃ§u des donnÃ©es :")
    print(df.head())
    print(f"\nğŸ“ˆ Statistiques :")
    print(df.describe())
```

**Lancer le script**
```powershell
cd services/service_stmodel
python scripts/generate_synthetic_data.py
```

---

### **Ã‰tape 1.2 : Exploration des donnÃ©es (1h)**

**CrÃ©er `notebooks/01_data_exploration.ipynb`**

```python
# Cellule 1 : Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Cellule 2 : Charger donnÃ©es
df = pd.read_csv('../data/raw/synthetic_water_quality.csv')
print(f"ğŸ“Š Dataset shape: {df.shape}")
df.head()

# Cellule 3 : VÃ©rifier valeurs manquantes
print("â“ Valeurs manquantes :")
print(df.isnull().sum())

# Cellule 4 : Statistiques descriptives
df.describe()

# Cellule 5 : Distribution des paramÃ¨tres
fig, axes = plt.subplots(2, 4, figsize=(16, 8))
parameters = ['ph', 'temperature', 'turbidite', 'oxygene_dissous', 
              'chlorophylle', 'qualite_score']

for i, param in enumerate(parameters):
    ax = axes[i // 4, i % 4]
    df[param].hist(bins=50, ax=ax)
    ax.set_title(f'Distribution {param}')
    ax.set_xlabel(param)
    
plt.tight_layout()
plt.show()

# Cellule 6 : CorrÃ©lations
plt.figure(figsize=(10, 8))
correlation = df[parameters].corr()
sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0)
plt.title('Matrice de corrÃ©lation')
plt.show()

# Cellule 7 : Ã‰volution temporelle
df['timestamp'] = pd.to_datetime(df['timestamp'])
df.set_index('timestamp').resample('D')['qualite_score'].mean().plot(figsize=(15, 5))
plt.title('Ã‰volution qualitÃ© de l\'eau dans le temps')
plt.ylabel('Score qualitÃ©')
plt.show()
```

---

### **Ã‰tape 1.3 : PrÃ©paration des donnÃ©es (2h)**

**CrÃ©er `src/ml/preprocessing.py`**

```python
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler, StandardScaler
import torch

class WaterQualityPreprocessor:
    """
    PrÃ©pare les donnÃ©es pour le modÃ¨le ConvLSTM
    """
    
    def __init__(self, sequence_length=24):
        """
        Args:
            sequence_length: Nombre de pas de temps pour sÃ©quences (ex: 24h)
        """
        self.sequence_length = sequence_length
        self.scaler = MinMaxScaler()
        self.feature_columns = None
        
    def prepare_data(self, df):
        """
        Nettoie et normalise les donnÃ©es
        
        Args:
            df: DataFrame avec colonnes timestamp, lat, lon, paramÃ¨tres
            
        Returns:
            X: Features normalisÃ©es
            y: Target (qualitÃ© Ã  prÃ©dire)
        """
        # 1. Trier par temps
        df = df.sort_values('timestamp').reset_index(drop=True)
        
        # 2. GÃ©rer valeurs manquantes
        df = df.fillna(df.mean(numeric_only=True))
        
        # 3. SÃ©lectionner features
        self.feature_columns = ['latitude', 'longitude', 'ph', 'temperature', 
                                'turbidite', 'oxygene_dissous', 'chlorophylle']
        
        # 4. Normaliser (0-1)
        X = self.scaler.fit_transform(df[self.feature_columns])
        
        # 5. Target = qualitÃ©
        y = df['qualite_score'].values
        
        return X, y
    
    def create_sequences(self, X, y, horizon=24):
        """
        CrÃ©e des sÃ©quences temporelles pour ConvLSTM
        
        Args:
            X: Features (n_samples, n_features)
            y: Targets (n_samples,)
            horizon: Horizon de prÃ©diction en heures
            
        Returns:
            X_seq: (n_sequences, sequence_length, n_features)
            y_seq: (n_sequences,) - qualitÃ© Ã  horizon
        """
        X_sequences = []
        y_sequences = []
        
        for i in range(len(X) - self.sequence_length - horizon):
            # SÃ©quence passÃ©e (24h par exemple)
            X_seq = X[i:i + self.sequence_length]
            
            # Target = qualitÃ© Ã  l'horizon (24h dans le futur)
            y_target = y[i + self.sequence_length + horizon - 1]
            
            X_sequences.append(X_seq)
            y_sequences.append(y_target)
        
        X_sequences = np.array(X_sequences)
        y_sequences = np.array(y_sequences)
        
        return X_sequences, y_sequences
    
    def to_torch(self, X, y):
        """Convertit numpy arrays en tensors PyTorch"""
        X_torch = torch.FloatTensor(X)
        y_torch = torch.FloatTensor(y)
        return X_torch, y_torch
    
    def create_spatial_grid(self, X, grid_size=10):
        """
        Transforme donnÃ©es en grille spatiale pour ConvLSTM
        
        Args:
            X: (n_sequences, sequence_length, n_features)
            grid_size: Taille de la grille (10x10 par exemple)
            
        Returns:
            X_grid: (n_sequences, sequence_length, n_features, grid_size, grid_size)
        """
        # TODO: ImplÃ©menter interpolation spatiale
        # Pour l'instant, duplication simple (Ã  amÃ©liorer)
        n_seq, seq_len, n_feat = X.shape
        X_grid = np.zeros((n_seq, seq_len, n_feat, grid_size, grid_size))
        
        for i in range(n_seq):
            for t in range(seq_len):
                # Remplir grille avec valeur moyenne (simplifiÃ©)
                X_grid[i, t, :, :, :] = X[i, t, :, np.newaxis, np.newaxis]
        
        return X_grid

# Exemple d'utilisation
if __name__ == "__main__":
    # Charger donnÃ©es
    df = pd.read_csv('../../data/raw/synthetic_water_quality.csv')
    
    # PrÃ©processeur
    preprocessor = WaterQualityPreprocessor(sequence_length=24)
    
    # PrÃ©parer
    X, y = preprocessor.prepare_data(df)
    print(f"âœ… Features shape: {X.shape}")
    print(f"âœ… Target shape: {y.shape}")
    
    # CrÃ©er sÃ©quences
    X_seq, y_seq = preprocessor.create_sequences(X, y, horizon=24)
    print(f"âœ… Sequences shape: {X_seq.shape}")
    print(f"âœ… Targets shape: {y_seq.shape}")
    
    # Convertir PyTorch
    X_torch, y_torch = preprocessor.to_torch(X_seq, y_seq)
    print(f"âœ… PyTorch tensors crÃ©Ã©s")
```

---

### **Ã‰tape 1.4 : ModÃ¨le ConvLSTM (3-4h)**

**CrÃ©er `src/ml/convlstm.py`**

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class ConvLSTMCell(nn.Module):
    """
    Cellule ConvLSTM : combine LSTM (temporel) + CNN (spatial)
    """
    
    def __init__(self, input_dim, hidden_dim, kernel_size, bias=True):
        """
        Args:
            input_dim: Nombre de channels input
            hidden_dim: Nombre de channels hidden state
            kernel_size: Taille du kernel convolutionnel
        """
        super(ConvLSTMCell, self).__init__()
        
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.kernel_size = kernel_size
        self.padding = kernel_size // 2
        self.bias = bias
        
        # Gates : input, forget, cell, output
        self.conv = nn.Conv2d(
            in_channels=self.input_dim + self.hidden_dim,
            out_channels=4 * self.hidden_dim,
            kernel_size=self.kernel_size,
            padding=self.padding,
            bias=self.bias
        )
    
    def forward(self, input_tensor, cur_state):
        """
        Args:
            input_tensor: (batch, input_dim, height, width)
            cur_state: (h_cur, c_cur) - hidden et cell states
            
        Returns:
            h_next, c_next: Nouveaux Ã©tats
        """
        h_cur, c_cur = cur_state
        
        # ConcatÃ©ner input et hidden state
        combined = torch.cat([input_tensor, h_cur], dim=1)
        
        # Appliquer convolution
        combined_conv = self.conv(combined)
        
        # SÃ©parer les 4 gates
        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)
        
        # Calcul des gates (formules LSTM)
        i = torch.sigmoid(cc_i)  # Input gate
        f = torch.sigmoid(cc_f)  # Forget gate
        o = torch.sigmoid(cc_o)  # Output gate
        g = torch.tanh(cc_g)     # Cell gate
        
        # Nouveau cell state
        c_next = f * c_cur + i * g
        
        # Nouveau hidden state
        h_next = o * torch.tanh(c_next)
        
        return h_next, c_next
    
    def init_hidden(self, batch_size, image_size):
        """Initialise les Ã©tats Ã  zÃ©ro"""
        height, width = image_size
        return (
            torch.zeros(batch_size, self.hidden_dim, height, width, 
                       device=self.conv.weight.device),
            torch.zeros(batch_size, self.hidden_dim, height, width,
                       device=self.conv.weight.device)
        )


class WaterQualityConvLSTM(nn.Module):
    """
    ModÃ¨le complet pour prÃ©diction qualitÃ© de l'eau
    """
    
    def __init__(self, input_dim=7, hidden_dims=[64, 32], 
                 kernel_size=3, num_layers=2):
        """
        Args:
            input_dim: Nombre de features (lat, lon, ph, temp, etc.)
            hidden_dims: Liste des dimensions hidden pour chaque couche
            kernel_size: Taille kernel convolutionnel
            num_layers: Nombre de couches ConvLSTM
        """
        super(WaterQualityConvLSTM, self).__init__()
        
        self.input_dim = input_dim
        self.hidden_dims = hidden_dims
        self.kernel_size = kernel_size
        self.num_layers = num_layers
        
        # CrÃ©er couches ConvLSTM
        cell_list = []
        for i in range(num_layers):
            cur_input_dim = input_dim if i == 0 else hidden_dims[i - 1]
            cell_list.append(
                ConvLSTMCell(
                    input_dim=cur_input_dim,
                    hidden_dim=hidden_dims[i],
                    kernel_size=kernel_size
                )
            )
        
        self.cell_list = nn.ModuleList(cell_list)
        
        # Couche de sortie (prÃ©diction qualitÃ©)
        self.output = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),  # Global pooling
            nn.Flatten(),
            nn.Linear(hidden_dims[-1], 32),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(32, 1)  # PrÃ©diction qualitÃ© (score 0-10)
        )
    
    def forward(self, x):
        """
        Args:
            x: (batch, seq_len, input_dim, height, width)
            
        Returns:
            pred: (batch, 1) - Score qualitÃ© prÃ©dit
        """
        batch_size, seq_len, _, height, width = x.size()
        
        # Initialiser Ã©tats cachÃ©s
        hidden_states = []
        for i in range(self.num_layers):
            hidden_states.append(
                self.cell_list[i].init_hidden(batch_size, (height, width))
            )
        
        # Passer sÃ©quence temporelle
        for t in range(seq_len):
            x_t = x[:, t, :, :, :]  # Frame au temps t
            
            for layer_idx in range(self.num_layers):
                # Input de cette couche
                if layer_idx == 0:
                    input_t = x_t
                else:
                    input_t = hidden_states[layer_idx - 1][0]
                
                # Passer par ConvLSTMCell
                h, c = self.cell_list[layer_idx](input_t, hidden_states[layer_idx])
                hidden_states[layer_idx] = (h, c)
        
        # DerniÃ¨re hidden state de derniÃ¨re couche
        last_hidden = hidden_states[-1][0]
        
        # PrÃ©diction
        pred = self.output(last_hidden)
        
        return pred


# VERSION SIMPLIFIÃ‰E pour dÃ©buter (sans grille spatiale)
class SimpleWaterQualityLSTM(nn.Module):
    """
    Version simplifiÃ©e : LSTM classique sans convolutions
    Plus facile pour dÃ©buter !
    """
    
    def __init__(self, input_dim=7, hidden_dim=64, num_layers=2):
        super(SimpleWaterQualityLSTM, self).__init__()
        
        self.lstm = nn.LSTM(
            input_size=input_dim,
            hidden_size=hidden_dim,
            num_layers=num_layers,
            batch_first=True,
            dropout=0.2
        )
        
        self.fc = nn.Sequential(
            nn.Linear(hidden_dim, 32),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(32, 1)
        )
    
    def forward(self, x):
        """
        Args:
            x: (batch, seq_len, input_dim)
        Returns:
            pred: (batch, 1)
        """
        # LSTM
        lstm_out, _ = self.lstm(x)
        
        # DerniÃ¨re sortie temporelle
        last_output = lstm_out[:, -1, :]
        
        # PrÃ©diction
        pred = self.fc(last_output)
        
        return pred


# Test du modÃ¨le
if __name__ == "__main__":
    # Test version simple
    model_simple = SimpleWaterQualityLSTM(input_dim=7, hidden_dim=64)
    x_simple = torch.randn(8, 24, 7)  # batch=8, seq=24h, features=7
    pred_simple = model_simple(x_simple)
    print(f"âœ… Simple LSTM output: {pred_simple.shape}")  # (8, 1)
    
    # Test ConvLSTM complet
    model_conv = WaterQualityConvLSTM(input_dim=7, hidden_dims=[64, 32])
    x_conv = torch.randn(8, 24, 7, 10, 10)  # avec grille spatiale 10x10
    pred_conv = model_conv(x_conv)
    print(f"âœ… ConvLSTM output: {pred_conv.shape}")  # (8, 1)
```

---

### **Ã‰tape 1.5 : EntraÃ®nement (2-3h)**

**CrÃ©er `src/ml/train.py`**

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import json
from datetime import datetime

from preprocessing import WaterQualityPreprocessor
from convlstm import SimpleWaterQualityLSTM, WaterQualityConvLSTM


class WaterQualityTrainer:
    """
    Classe pour entraÃ®ner les modÃ¨les
    """
    
    def __init__(self, model, device='cuda' if torch.cuda.is_available() else 'cpu'):
        self.model = model.to(device)
        self.device = device
        self.history = {'train_loss': [], 'val_loss': []}
    
    def train(self, train_loader, val_loader, epochs=50, lr=0.001):
        """
        EntraÃ®ne le modÃ¨le
        
        Args:
            train_loader: DataLoader train
            val_loader: DataLoader validation
            epochs: Nombre d'Ã©poques
            lr: Learning rate
        """
        criterion = nn.MSELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=lr)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='min', patience=5, factor=0.5
        )
        
        best_val_loss = float('inf')
        
        for epoch in range(epochs):
            # TRAIN
            self.model.train()
            train_loss = 0.0
            
            for batch_X, batch_y in train_loader:
                batch_X = batch_X.to(self.device)
                batch_y = batch_y.to(self.device)
                
                # Forward
                optimizer.zero_grad()
                predictions = self.model(batch_X).squeeze()
                loss = criterion(predictions, batch_y)
                
                # Backward
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
            
            train_loss /= len(train_loader)
            
            # VALIDATION
            self.model.eval()
            val_loss = 0.0
            
            with torch.no_grad():
                for batch_X, batch_y in val_loader:
                    batch_X = batch_X.to(self.device)
                    batch_y = batch_y.to(self.device)
                    
                    predictions = self.model(batch_X).squeeze()
                    loss = criterion(predictions, batch_y)
                    val_loss += loss.item()
            
            val_loss /= len(val_loader)
            
            # Historique
            self.history['train_loss'].append(train_loss)
            self.history['val_loss'].append(val_loss)
            
            # Learning rate scheduling
            scheduler.step(val_loss)
            
            # Affichage
            if (epoch + 1) % 5 == 0:
                print(f"Epoch {epoch+1}/{epochs} - "
                      f"Train Loss: {train_loss:.4f} - "
                      f"Val Loss: {val_loss:.4f}")
            
            # Sauvegarder meilleur modÃ¨le
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                self.save_model('../../models/best_model.pth')
        
        print(f"\nâœ… EntraÃ®nement terminÃ© ! Meilleure val_loss: {best_val_loss:.4f}")
    
    def save_model(self, path):
        """Sauvegarde le modÃ¨le"""
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'history': self.history
        }, path)
    
    def load_model(self, path):
        """Charge le modÃ¨le"""
        checkpoint = torch.load(path)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.history = checkpoint.get('history', {})
    
    def plot_history(self):
        """Affiche courbes d'apprentissage"""
        plt.figure(figsize=(10, 6))
        plt.plot(self.history['train_loss'], label='Train Loss')
        plt.plot(self.history['val_loss'], label='Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss (MSE)')
        plt.title('Courbes d\'apprentissage')
        plt.legend()
        plt.grid(True)
        plt.savefig('../../models/training_history.png')
        plt.show()


def main():
    """
    Script principal d'entraÃ®nement
    """
    print("ğŸš€ DÃ©but de l'entraÃ®nement du modÃ¨le...")
    
    # 1. Charger donnÃ©es
    print("\nğŸ“Š Chargement des donnÃ©es...")
    df = pd.read_csv('../../data/raw/synthetic_water_quality.csv')
    print(f"âœ… {len(df)} Ã©chantillons chargÃ©s")
    
    # 2. PrÃ©processing
    print("\nğŸ”„ PrÃ©traitement des donnÃ©es...")
    preprocessor = WaterQualityPreprocessor(sequence_length=24)
    X, y = preprocessor.prepare_data(df)
    X_seq, y_seq = preprocessor.create_sequences(X, y, horizon=24)
    print(f"âœ… {len(X_seq)} sÃ©quences crÃ©Ã©es")
    
    # 3. Split train/val/test
    X_train, X_temp, y_train, y_temp = train_test_split(
        X_seq, y_seq, test_size=0.3, random_state=42
    )
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, test_size=0.5, random_state=42
    )
    
    print(f"âœ… Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}")
    
    # 4. Convertir en tensors PyTorch
    X_train_t = torch.FloatTensor(X_train)
    y_train_t = torch.FloatTensor(y_train)
    X_val_t = torch.FloatTensor(X_val)
    y_val_t = torch.FloatTensor(y_val)
    
    # 5. DataLoaders
    train_dataset = TensorDataset(X_train_t, y_train_t)
    val_dataset = TensorDataset(X_val_t, y_val_t)
    
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    
    # 6. CrÃ©er modÃ¨le
    print("\nğŸ§  CrÃ©ation du modÃ¨le...")
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"âœ… Device: {device}")
    
    model = SimpleWaterQualityLSTM(
        input_dim=7,
        hidden_dim=64,
        num_layers=2
    )
    
    # 7. EntraÃ®ner
    print("\nğŸ‹ï¸ EntraÃ®nement...")
    trainer = WaterQualityTrainer(model, device=device)
    trainer.train(train_loader, val_loader, epochs=50, lr=0.001)
    
    # 8. Visualiser
    print("\nğŸ“ˆ GÃ©nÃ©ration des graphiques...")
    trainer.plot_history()
    
    # 9. Ã‰valuation finale
    print("\nğŸ¯ Ã‰valuation sur test set...")
    model.eval()
    X_test_t = torch.FloatTensor(X_test).to(device)
    y_test_t = torch.FloatTensor(y_test).to(device)
    
    with torch.no_grad():
        predictions = model(X_test_t).squeeze().cpu().numpy()
    
    test_mse = np.mean((predictions - y_test) ** 2)
    test_mae = np.mean(np.abs(predictions - y_test))
    
    print(f"âœ… Test MSE: {test_mse:.4f}")
    print(f"âœ… Test MAE: {test_mae:.4f}")
    
    # 10. Sauvegarder mÃ©tadonnÃ©es
    model_info = {
        'model_type': 'SimpleWaterQualityLSTM',
        'input_dim': 7,
        'hidden_dim': 64,
        'num_layers': 2,
        'sequence_length': 24,
        'horizon': 24,
        'test_mse': float(test_mse),
        'test_mae': float(test_mae),
        'trained_on': datetime.now().isoformat(),
        'dataset': 'synthetic_water_quality',
        'n_samples': len(df)
    }
    
    with open('../../models/model_info.json', 'w') as f:
        json.dump(model_info, f, indent=2)
    
    print("\nâœ… EntraÃ®nement terminÃ© avec succÃ¨s !")
    print(f"ğŸ“ ModÃ¨le sauvegardÃ© dans models/best_model.pth")


if __name__ == "__main__":
    main()
```

**Lancer l'entraÃ®nement**
```powershell
cd services/service_stmodel
python src/ml/train.py
```

---

### **Ã‰tape 1.6 : API avec modÃ¨le entraÃ®nÃ© (2h)**

**CrÃ©er `src/main.py`**

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import torch
import numpy as np
import json
from typing import List, Optional
from datetime import datetime

# Imports locaux (Ã  adapter selon structure)
from ml.convlstm import SimpleWaterQualityLSTM
from ml.preprocessing import WaterQualityPreprocessor

# Initialiser FastAPI
app = FastAPI(
    title="AquaWatch STModel API",
    description="API de prÃ©diction de la qualitÃ© de l'eau avec modÃ¨les spatio-temporels",
    version="1.0.0"
)

# Charger le modÃ¨le au dÃ©marrage
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = None
model_info = None
preprocessor = WaterQualityPreprocessor(sequence_length=24)

@app.on_event("startup")
async def load_model():
    """Charge le modÃ¨le entraÃ®nÃ© au dÃ©marrage"""
    global model, model_info
    
    try:
        # Charger mÃ©tadonnÃ©es
        with open('../models/model_info.json', 'r') as f:
            model_info = json.load(f)
        
        # CrÃ©er modÃ¨le
        model = SimpleWaterQualityLSTM(
            input_dim=model_info['input_dim'],
            hidden_dim=model_info['hidden_dim'],
            num_layers=model_info['num_layers']
        )
        
        # Charger poids
        checkpoint = torch.load('../models/best_model.pth', map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(device)
        model.eval()
        
        print(f"âœ… ModÃ¨le chargÃ© avec succÃ¨s ! MSE: {model_info['test_mse']:.4f}")
    except Exception as e:
        print(f"âš ï¸ Erreur chargement modÃ¨le: {e}")
        print("â„¹ï¸ L'API fonctionnera en mode dÃ©gradÃ©")


# SchÃ©mas Pydantic
class WaterQualityMeasurement(BaseModel):
    latitude: float
    longitude: float
    ph: float
    temperature: float
    turbidite: float
    oxygene_dissous: float
    chlorophylle: float

class PredictionRequest(BaseModel):
    measurements: List[WaterQualityMeasurement]  # 24 derniÃ¨res heures
    horizon: int = 24  # Horizon de prÃ©diction en heures

class PredictionResponse(BaseModel):
    prediction_id: str
    qualite_score: float
    qualite_categorie: str  # EXCELLENTE, BONNE, MOYENNE, MAUVAISE
    confiance: float
    horizon_heures: int
    timestamp: str


# Routes API
@app.get("/")
async def root():
    """Page d'accueil de l'API"""
    return {
        "service": "STModel - PrÃ©diction qualitÃ© de l'eau",
        "version": "1.0.0",
        "status": "operational",
        "model_loaded": model is not None
    }

@app.get("/health")
async def health():
    """VÃ©rification santÃ© du service"""
    return {
        "status": "healthy",
        "service": "stmodel",
        "pytorch_version": torch.__version__,
        "device": device,
        "model_loaded": model is not None
    }

@app.get("/api/model/info")
async def get_model_info():
    """Informations sur le modÃ¨le actuel"""
    if model_info is None:
        raise HTTPException(status_code=503, detail="ModÃ¨le non chargÃ©")
    
    return model_info

@app.post("/api/predictions/create", response_model=PredictionResponse)
async def create_prediction(request: PredictionRequest):
    """
    CrÃ©e une nouvelle prÃ©diction de qualitÃ© de l'eau
    
    NÃ©cessite 24 derniÃ¨res mesures pour prÃ©dire la qualitÃ© future
    """
    if model is None:
        raise HTTPException(status_code=503, detail="ModÃ¨le non disponible")
    
    if len(request.measurements) < 24:
        raise HTTPException(
            status_code=400, 
            detail=f"24 mesures requises, {len(request.measurements)} fournies"
        )
    
    try:
        # 1. Convertir en array numpy
        features = []
        for m in request.measurements[-24:]:  # 24 derniÃ¨res
            features.append([
                m.latitude, m.longitude, m.ph, m.temperature,
                m.turbidite, m.oxygene_dissous, m.chlorophylle
            ])
        
        X = np.array(features)
        
        # 2. Normaliser
        X_normalized = preprocessor.scaler.fit_transform(X)
        
        # 3. Convertir en tensor
        X_tensor = torch.FloatTensor(X_normalized).unsqueeze(0).to(device)
        
        # 4. PrÃ©diction
        with torch.no_grad():
            pred_score = model(X_tensor).item()
        
        # 5. CatÃ©goriser
        if pred_score >= 8:
            categorie = "EXCELLENTE"
            confiance = 0.9
        elif pred_score >= 6:
            categorie = "BONNE"
            confiance = 0.85
        elif pred_score >= 4:
            categorie = "MOYENNE"
            confiance = 0.8
        else:
            categorie = "MAUVAISE"
            confiance = 0.75
        
        # 6. RÃ©ponse
        return PredictionResponse(
            prediction_id=f"PRED_{datetime.now().strftime('%Y%m%d%H%M%S')}",
            qualite_score=round(pred_score, 2),
            qualite_categorie=categorie,
            confiance=confiance,
            horizon_heures=request.horizon,
            timestamp=datetime.now().isoformat()
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur prÃ©diction: {str(e)}")


@app.get("/api/predictions/latest")
async def get_latest_predictions():
    """
    Retourne les derniÃ¨res prÃ©dictions (mock pour Phase 1)
    """
    # TODO: RÃ©cupÃ©rer depuis la base de donnÃ©es
    return {
        "predictions": [
            {
                "prediction_id": "PRED001",
                "qualite_score": 7.2,
                "qualite_categorie": "BONNE",
                "timestamp": "2025-10-27T10:00:00"
            }
        ]
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

**Tester l'API**
```powershell
# DÃ©marrer
cd services/service_stmodel
python src/main.py

# Tester health
curl http://localhost:8000/health

# Tester infos modÃ¨le
curl http://localhost:8000/api/model/info
```

---

## ğŸ”„ PHASE 2 : INTÃ‰GRATION AVEC APIs DE BILAL

### **Ã‰tape 2.1 : Client API pour Bilal (1h)**

**CrÃ©er `src/data/api_client.py`**

```python
import requests
from typing import List, Dict, Optional
import pandas as pd
from datetime import datetime, timedelta

class BilalAPIClient:
    """
    Client pour rÃ©cupÃ©rer donnÃ©es depuis les services de Bilal
    """
    
    def __init__(self, capteurs_url="http://service_capteurs:8000", 
                 satellite_url="http://service_satellite:8000"):
        self.capteurs_url = capteurs_url
        self.satellite_url = satellite_url
    
    def get_capteurs_data(self, hours=24) -> List[Dict]:
        """
        RÃ©cupÃ¨re donnÃ©es capteurs des derniÃ¨res heures
        
        Args:
            hours: Nombre d'heures Ã  rÃ©cupÃ©rer
            
        Returns:
            Liste de mesures capteurs
        """
        try:
            response = requests.get(
                f"{self.capteurs_url}/api/capteurs/data/latest",
                params={"hours": hours},
                timeout=10
            )
            response.raise_for_status()
            data = response.json()
            
            return data.get('capteurs', [])
        
        except requests.exceptions.RequestException as e:
            print(f"âš ï¸ Erreur API Capteurs: {e}")
            return []
    
    def get_satellite_data(self, latitude: float, longitude: float, 
                          radius_km: float = 5) -> Dict:
        """
        RÃ©cupÃ¨re indices satellite pour une zone
        
        Args:
            latitude: Latitude centre
            longitude: Longitude centre
            radius_km: Rayon de recherche
            
        Returns:
            Indices satellites (chlorophylle, turbiditÃ©, etc.)
        """
        try:
            response = requests.get(
                f"{self.satellite_url}/api/satellite/indices/latest",
                params={
                    "latitude": latitude,
                    "longitude": longitude,
                    "radius_km": radius_km
                },
                timeout=10
            )
            response.raise_for_status()
            data = response.json()
            
            return data.get('indices', {})
        
        except requests.exceptions.RequestException as e:
            print(f"âš ï¸ Erreur API Satellite: {e}")
            return {}
    
    def combine_data(self, capteurs_data: List[Dict], 
                     satellite_data: Dict) -> pd.DataFrame:
        """
        Fusionne donnÃ©es capteurs + satellite
        
        Returns:
            DataFrame avec toutes les features
        """
        # Convertir capteurs en DataFrame
        df_capteurs = pd.DataFrame(capteurs_data)
        
        # Ajouter donnÃ©es satellite
        if satellite_data:
            for key, value in satellite_data.items():
                df_capteurs[key] = value
        
        return df_capteurs


# Exemple d'utilisation
if __name__ == "__main__":
    client = BilalAPIClient()
    
    # RÃ©cupÃ©rer donnÃ©es
    capteurs = client.get_capteurs_data(hours=24)
    print(f"âœ… {len(capteurs)} mesures capteurs rÃ©cupÃ©rÃ©es")
    
    if capteurs:
        # RÃ©cupÃ©rer satellite pour premiÃ¨re mesure
        first_measure = capteurs[0]
        satellite = client.get_satellite_data(
            latitude=first_measure['latitude'],
            longitude=first_measure['longitude']
        )
        print(f"âœ… Indices satellite: {satellite}")
        
        # Combiner
        df = client.combine_data(capteurs, satellite)
        print(f"\nğŸ“Š DataFrame combinÃ© :\n{df.head()}")
```

---

### **Ã‰tape 2.2 : Adapter le service de prÃ©diction (30 min)**

**Modifier `src/services/prediction_service.py`**

```python
import torch
import numpy as np
from typing import Dict, Optional
from datetime import datetime

from ml.convlstm import SimpleWaterQualityLSTM
from ml.preprocessing import WaterQualityPreprocessor
from data.api_client import BilalAPIClient  # NOUVEAU !

class PredictionService:
    """
    Service de prÃ©diction qui peut utiliser :
    - Phase 1 : DonnÃ©es du dataset
    - Phase 2 : APIs de Bilal
    """
    
    def __init__(self, model_path: str, use_api: bool = False):
        """
        Args:
            model_path: Chemin vers le modÃ¨le .pth
            use_api: True = utiliser APIs Bilal, False = dataset local
        """
        self.model = self.load_model(model_path)
        self.preprocessor = WaterQualityPreprocessor(sequence_length=24)
        self.use_api = use_api
        
        if self.use_api:
            self.api_client = BilalAPIClient()
    
    def load_model(self, path: str):
        """Charge le modÃ¨le PyTorch"""
        model = SimpleWaterQualityLSTM(input_dim=7, hidden_dim=64, num_layers=2)
        checkpoint = torch.load(path, map_location='cpu')
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        return model
    
    def get_data_from_api(self) -> Optional[np.ndarray]:
        """
        PHASE 2 : RÃ©cupÃ¨re donnÃ©es depuis APIs Bilal
        """
        if not self.use_api:
            return None
        
        # RÃ©cupÃ©rer donnÃ©es capteurs (24h)
        capteurs_data = self.api_client.get_capteurs_data(hours=24)
        
        if not capteurs_data or len(capteurs_data) < 24:
            print("âš ï¸ Pas assez de donnÃ©es capteurs")
            return None
        
        # RÃ©cupÃ©rer satellite pour premiÃ¨re localisation
        first_loc = capteurs_data[0]
        satellite_data = self.api_client.get_satellite_data(
            latitude=first_loc['latitude'],
            longitude=first_loc['longitude']
        )
        
        # Combiner
        df = self.api_client.combine_data(capteurs_data, satellite_data)
        
        # Extraire features
        features = []
        for _, row in df.iterrows():
            features.append([
                row['latitude'],
                row['longitude'],
                row['ph'],
                row['temperature'],
                row['turbidite'],
                row['oxygene_dissous'],
                row.get('chlorophylle', 0)  # Depuis satellite
            ])
        
        return np.array(features)
    
    def predict(self, data: Optional[np.ndarray] = None) -> Dict:
        """
        Fait une prÃ©diction
        
        Args:
            data: Si None, utilise API (Phase 2) ou dataset (Phase 1)
        
        Returns:
            Dictionnaire avec prÃ©diction
        """
        # RÃ©cupÃ©rer donnÃ©es
        if data is None:
            if self.use_api:
                data = self.get_data_from_api()
            else:
                # Phase 1 : donnÃ©es mock
                print("â„¹ï¸ Mode Phase 1 : utilisation de donnÃ©es fictives")
                data = self.generate_mock_data()
        
        if data is None:
            raise ValueError("Aucune donnÃ©e disponible")
        
        # Normaliser
        X_normalized = self.preprocessor.scaler.fit_transform(data)
        
        # Convertir en tensor
        X_tensor = torch.FloatTensor(X_normalized).unsqueeze(0)
        
        # PrÃ©diction
        with torch.no_grad():
            pred_score = self.model(X_tensor).item()
        
        # CatÃ©goriser
        categorie = self.categorize_quality(pred_score)
        
        return {
            'prediction_id': f"PRED_{datetime.now().strftime('%Y%m%d%H%M%S')}",
            'qualite_score': round(pred_score, 2),
            'qualite_categorie': categorie,
            'confiance': 0.85,
            'timestamp': datetime.now().isoformat(),
            'source': 'api' if self.use_api else 'dataset'
        }
    
    def categorize_quality(self, score: float) -> str:
        """CatÃ©gorise le score de qualitÃ©"""
        if score >= 8:
            return "EXCELLENTE"
        elif score >= 6:
            return "BONNE"
        elif score >= 4:
            return "MOYENNE"
        else:
            return "MAUVAISE"
    
    def generate_mock_data(self) -> np.ndarray:
        """GÃ©nÃ¨re donnÃ©es fictives pour Phase 1"""
        # 24 mesures fictives
        return np.random.randn(24, 7)
```

---

### **Ã‰tape 2.3 : Configuration avec variable d'environnement (15 min)**

**Modifier `src/config.py`**

```python
import os
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    """Configuration de l'application"""
    
    # GÃ©nÃ©ral
    SERVICE_NAME: str = "STModel"
    VERSION: str = "1.0.0"
    
    # Base de donnÃ©es
    DATABASE_URL: str = os.getenv(
        "DATABASE_URL",
        "postgresql://predictions_user:predictions_pass_2025@db_predictions:5432/predictions_db"
    )
    
    # Redis
    REDIS_URL: str = os.getenv("REDIS_URL", "redis://redis_queue:6379")
    
    # APIs externes (Phase 2)
    CAPTEURS_API_URL: str = os.getenv("CAPTEURS_API_URL", "http://service_capteurs:8000")
    SATELLITE_API_URL: str = os.getenv("SATELLITE_API_URL", "http://service_satellite:8000")
    
    # ModÃ¨le
    USE_API_DATA: bool = os.getenv("USE_API_DATA", "false").lower() == "true"
    MODEL_PATH: str = os.getenv("MODEL_PATH", "../models/best_model.pth")
    
    class Config:
        env_file = ".env"

settings = Settings()
```

**CrÃ©er `.env` local**
```bash
# Phase 1 : Dataset local
USE_API_DATA=false

# Phase 2 : APIs Bilal (activer quand prÃªt)
# USE_API_DATA=true
# CAPTEURS_API_URL=http://service_capteurs:8000
# SATELLITE_API_URL=http://service_satellite:8000
```

---

### **Ã‰tape 2.4 : Transition Phase 1 â†’ Phase 2 (Facile !)**

Quand Bilal a terminÃ© ses services :

1. **VÃ©rifier que les APIs de Bilal fonctionnent**
```powershell
curl http://localhost:8001/api/capteurs/data/latest
curl http://localhost:8002/api/satellite/indices/latest
```

2. **Activer mode API dans votre service**
```bash
# Dans .env
USE_API_DATA=true
```

3. **RedÃ©marrer votre service**
```powershell
docker compose restart service_stmodel
```

4. **Tester**
```powershell
curl http://localhost:8003/api/predictions/create
```

5. **RÃ©-entraÃ®ner le modÃ¨le avec vraies donnÃ©es** (optionnel)
```python
# Collecter 1 semaine de donnÃ©es depuis APIs
# Puis relancer train.py
python src/ml/train.py --use-api-data
```

**C'EST TOUT ! ğŸ‰**

---

## ğŸ³ COMMANDES DOCKER UTILES

### **DÃ©veloppement local (Phase 1)**
```powershell
# Juste votre service + base dÃ©diÃ©e
docker compose up db_predictions redis_queue -d
docker compose up service_stmodel
```

### **IntÃ©gration complÃ¨te (Phase 2)**
```powershell
# Tous les services
docker compose up
```

### **Rebuild aprÃ¨s modifications**
```powershell
# Si modification requirements.txt
docker compose build service_stmodel

# Si modification code seulement
docker compose restart service_stmodel
```

### **Logs**
```powershell
docker compose logs -f service_stmodel
```

---

## ğŸ“Š RÃ‰SUMÃ‰ DES PHASES

### **PHASE 1 (MAINTENANT) - 1-2 SEMAINES**

âœ… **Avantages** :
- IndÃ©pendant de Bilal
- ModÃ¨le validÃ© et fonctionnel
- API complÃ¨te et testÃ©e

âœ… **Livrables** :
- ModÃ¨le ConvLSTM entraÃ®nÃ©
- API REST opÃ©rationnelle
- Documentation complÃ¨te

### **PHASE 2 (QUAND BILAL PRÃŠT) - 2-3 JOURS**

âœ… **Transition facile** :
- Changer 1 variable (`USE_API_DATA=true`)
- Tester intÃ©gration
- RÃ©-entraÃ®ner si besoin

âœ… **Avantages** :
- DonnÃ©es rÃ©elles en temps rÃ©el
- IntÃ©gration complÃ¨te microservices
- PrÃ©dictions prÃ©cises

---

## ğŸ¯ CHECKLIST DE PROGRESSION

### **Semaine 1**
- [ ] TÃ©lÃ©charger/gÃ©nÃ©rer dataset
- [ ] Explorer donnÃ©es (notebook)
- [ ] ImplÃ©menter preprocessing
- [ ] Tester modÃ¨le simple

### **Semaine 2**
- [ ] EntraÃ®ner modÃ¨le complet
- [ ] Ã‰valuer performance
- [ ] CrÃ©er API FastAPI
- [ ] Tester endpoints

### **Semaine 3**
- [ ] Connexion PostgreSQL
- [ ] Stockage prÃ©dictions
- [ ] Communication Redis
- [ ] Tests intÃ©gration

### **Quand Bilal prÃªt**
- [ ] ImplÃ©menter client API
- [ ] Activer mode API
- [ ] Tests avec vraies donnÃ©es
- [ ] RÃ©-entraÃ®nement optionnel

---

## ğŸ’¡ CONSEILS FINAUX

1. **Commencez simple** : LSTM basique avant ConvLSTM complet
2. **Testez souvent** : Chaque composant indÃ©pendamment
3. **Logs partout** : Pour dÃ©bugger facilement
4. **Documentation** : Notez vos dÃ©cisions et rÃ©sultats
5. **Git rÃ©guliÃ¨rement** : Commit aprÃ¨s chaque Ã©tape

---

## ğŸ†˜ TROUBLESHOOTING

### **ModÃ¨le ne converge pas**
- RÃ©duire learning rate
- Normaliser les donnÃ©es
- Simplifier architecture

### **API ne rÃ©pond pas**
- VÃ©rifier logs Docker
- Tester health endpoint
- VÃ©rifier ports

### **DonnÃ©es manquantes**
- Mode fallback avec donnÃ©es mock
- Logs pour identifier le problÃ¨me
- VÃ©rifier APIs de Bilal

---

**ğŸš€ Bonne chance ! Vous Ãªtes prÃªt Ã  dÃ©velopper un modÃ¨le AI professionnel ! ğŸŒŠ**
