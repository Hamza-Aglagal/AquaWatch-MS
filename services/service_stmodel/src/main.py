"""
Application FastAPI principale - STModel Service
Simple et clair
"""
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import uvicorn

from .api.routes import router, prediction_service, redis_publisher


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gestion du cycle de vie - Charge le mod√®le au d√©marrage"""
    print("=" * 60)
    print("üöÄ D√©marrage STModel Service...")
    print("=" * 60)
    
    # Charger le mod√®le au d√©marrage
    success = prediction_service.load_model()
    
    if success:
        print("‚úÖ Service pr√™t √† recevoir des requ√™tes")
    else:
        print("‚ö†Ô∏è Service d√©marr√© SANS mod√®le charg√©")
    
    # Connecter Redis (optionnel, ne bloque pas si √©chec)
    redis_publisher.connect()
    
    print("=" * 60)
    
    yield
    
    # Nettoyage √† l'arr√™t
    print("üõë Arr√™t du service...")


# Cr√©er l'application FastAPI
app = FastAPI(
    title="AquaWatch - STModel Service",
    description="Service de pr√©diction de qualit√© d'eau avec LSTM",
    version="1.0.0",
    lifespan=lifespan
)

# Configuration CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Inclure les routes API
app.include_router(router)


@app.get("/")
async def root():
    """Page d'accueil de l'API"""
    return {
        "service": "STModel",
        "version": "1.0.0",
        "description": "Pr√©diction qualit√© d'eau avec LSTM",
        "status": "running",
        "model_loaded": prediction_service.is_ready(),
        "endpoints": {
            "health": "/health",
            "docs": "/docs",
            "model_info": "/api/model/info",
            "create_prediction": "/api/predictions/create",
            "latest_predictions": "/api/predictions/latest"
        }
    }


@app.get("/health")
async def health():
    """Health check pour Docker"""
    return {
        "status": "healthy" if prediction_service.is_ready() else "degraded",
        "service": "stmodel",
        "model_loaded": prediction_service.is_ready()
    }


if __name__ == "__main__":
    # D√©marrer le serveur
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True
    )
