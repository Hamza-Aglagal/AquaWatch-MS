"""
TÃ©lÃ©chargement des donnÃ©es satellites Sentinel-2 via Google Earth Engine

Ce script :
1. Charge le dataset capteurs nettoyÃ©
2. Extrait les coordonnÃ©es GPS uniques
3. Pour chaque station, tÃ©lÃ©charge indices satellites (NDWI, chlorophylle, turbiditÃ©)
4. Sauvegarde dans data/raw/satellites/sentinel2_data.csv

Auteur: Hamza
Date: 2 novembre 2025
"""

import ee
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time
import os

# ============================================================================
# CONFIGURATION
# ============================================================================

# Fichier capteurs nettoyÃ© (source des coordonnÃ©es GPS)
CAPTEURS_FILE = 'data/processed/capteurs_cleaned.csv'

# Fichier de sortie
OUTPUT_FILE = 'data/raw/satellites/sentinel2_data.csv'

# Fichier checkpoint (pour reprendre en cas d'interruption)
CHECKPOINT_FILE = 'data/raw/satellites/.checkpoint_stations.txt'

# PÃ©riode de tÃ©lÃ©chargement
# On va utiliser les dates du dataset capteurs
START_DATE = None  # Sera dÃ©fini automatiquement
END_DATE = None    # Sera dÃ©fini automatiquement

# Nombre de stations Ã  traiter (pour test, mettre 10-20)
# Mettre None pour traiter toutes les stations
MAX_STATIONS = None  # âœ… TOUTES LES STATIONS

# FenÃªtre de recherche autour de la date capteur (jours)
# MODE COMPLET : TÃ©lÃ©charger TOUTES les images disponibles
DATE_WINDOW = None  # None = toute la pÃ©riode 2015-2022

# Seuil de couverture nuageuse (%)
CLOUD_COVER_MAX = 50  # AugmentÃ© Ã  50% pour avoir plus d'images


# ============================================================================
# FONCTIONS UTILITAIRES
# ============================================================================

def calculate_ndwi(image):
    """
    Calcule NDWI (Normalized Difference Water Index)
    NDWI = (GREEN - NIR) / (GREEN + NIR)
    
    Valeurs :
    - > 0.3 : Eau
    - 0 Ã  0.3 : Humide
    - < 0 : Sec
    """
    green = image.select('B3')  # Bande verte
    nir = image.select('B8')    # Proche infrarouge
    
    ndwi = green.subtract(nir).divide(green.add(nir)).rename('NDWI')
    return ndwi


def calculate_chlorophyll(image):
    """
    Calcule indice de chlorophylle (proxy)
    Utilise ratio de bandes sensibles Ã  la chlorophylle
    
    Chlorophyll Index = B4 / B3 (Rouge / Vert)
    """
    red = image.select('B4')
    green = image.select('B3')
    
    chlor = red.divide(green).rename('chlorophyll_index')
    return chlor


def calculate_turbidity(image):
    """
    Calcule indice de turbiditÃ© optique
    BasÃ© sur rÃ©flectance dans le rouge
    
    Plus la valeur est haute, plus l'eau est trouble
    """
    red = image.select('B4')
    turbidity = red.multiply(100).rename('turbidity_index')
    return turbidity


def calculate_temperature(image):
    """
    Extrait tempÃ©rature de surface (bande thermique)
    Note: Sentinel-2 n'a pas de bande thermique
    On utilise une approximation ou on retourne None
    """
    # Sentinel-2 n'a pas de vraie bande thermique
    # On retourne None pour cette version
    return None


def load_checkpoint():
    """
    Charge la liste des stations dÃ©jÃ  tÃ©lÃ©chargÃ©es
    """
    if os.path.exists(CHECKPOINT_FILE):
        with open(CHECKPOINT_FILE, 'r') as f:
            return set(line.strip() for line in f)
    return set()


def save_checkpoint(station_id):
    """
    Sauvegarde une station comme terminÃ©e
    """
    with open(CHECKPOINT_FILE, 'a') as f:
        f.write(f"{station_id}\n")


def save_partial_results(df_station, is_first=False):
    """
    Sauvegarde progressive des rÃ©sultats
    Ajoute les nouvelles donnÃ©es au fichier existant
    """
    if is_first and os.path.exists(OUTPUT_FILE):
        # Si fichier existe dÃ©jÃ , on continue (mode append)
        df_station.to_csv(OUTPUT_FILE, mode='a', header=False, index=False)
    elif is_first:
        # Premier enregistrement, crÃ©er fichier avec header
        df_station.to_csv(OUTPUT_FILE, mode='w', header=True, index=False)
    else:
        # Ajouter sans header
        df_station.to_csv(OUTPUT_FILE, mode='a', header=False, index=False)


def extract_indices_for_station(lat, lon, start_date, end_date):
    """
    Extrait TOUTES les indices satellites disponibles pour une station
    
    Args:
        lat: Latitude
        lon: Longitude
        start_date: Date dÃ©but (string 'YYYY-MM-DD')
        end_date: Date fin (string 'YYYY-MM-DD')
    
    Returns:
        DataFrame avec indices par date
    """
    # CrÃ©er un point
    point = ee.Geometry.Point([lon, lat])
    
    # Charger collection Sentinel-2 (Surface Reflectance - Version harmonisÃ©e)
    collection = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \
        .filterBounds(point) \
        .filterDate(start_date, end_date) \
        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', CLOUD_COVER_MAX))
    
    # VÃ©rifier si des images disponibles
    count = collection.size().getInfo()
    if count == 0:
        return pd.DataFrame()
    
    print(f"    ğŸ“¸ {count} images disponibles")
    
    # RÃ©cupÃ©rer liste des images
    images = collection.toList(count)
    
    results = []
    
    for i in range(count):
        try:
            # RÃ©cupÃ©rer image
            img = ee.Image(images.get(i))
            
            # Calculer indices
            ndwi = calculate_ndwi(img)
            chlor = calculate_chlorophyll(img)
            turb = calculate_turbidity(img)
            
            # Combiner tous les indices
            combined = ndwi.addBands([chlor, turb])
            
            # Extraire valeurs au point
            values = combined.reduceRegion(
                reducer=ee.Reducer.mean(),
                geometry=point,
                scale=10,  # RÃ©solution 10m
                maxPixels=1e9
            ).getInfo()
            
            # RÃ©cupÃ©rer date de l'image
            date_ms = img.get('system:time_start').getInfo()
            date = datetime.fromtimestamp(date_ms / 1000).strftime('%Y-%m-%d')
            
            # Ajouter au rÃ©sultat
            results.append({
                'date': date,
                'latitude': lat,
                'longitude': lon,
                'NDWI': values.get('NDWI'),
                'chlorophyll_index': values.get('chlorophyll_index'),
                'turbidity_index': values.get('turbidity_index'),
                'temperature_surface': None  # Sentinel-2 n'a pas de thermique
            })
            
            # Afficher progression tous les 50 images
            if (i+1) % 50 == 0:
                print(f"      â³ {i+1}/{count} images traitÃ©es...")
            
        except Exception as e:
            print(f"      âš ï¸  Erreur sur image {i+1}: {str(e)[:50]}")
            continue
    
    return pd.DataFrame(results)


# ============================================================================
# SCRIPT PRINCIPAL
# ============================================================================

def main():
    print("ğŸ›°ï¸  TÃ‰LÃ‰CHARGEMENT DONNÃ‰ES SATELLITES SENTINEL-2")
    print("=" * 70)
    print()
    
    # Initialiser Earth Engine
    print("ğŸ”§ Initialisation Google Earth Engine...")
    try:
        ee.Initialize(project='aquawatch-stmodel')
        print("âœ… Earth Engine initialisÃ©")
        print(f"ğŸ“¦ Projet : aquawatch-stmodel")
    except Exception as e:
        print("âŒ ERREUR : Impossible d'initialiser Earth Engine")
        print(f"Message : {str(e)}")
        print()
        print("ğŸ”§ Solution : Lance cette commande dans le terminal :")
        print("   earthengine authenticate --project aquawatch-stmodel")
        return
    print()
    
    # Charger dataset capteurs
    print("ğŸ“‚ Chargement dataset capteurs...")
    if not os.path.exists(CAPTEURS_FILE):
        print(f"âŒ ERREUR : Fichier introuvable : {CAPTEURS_FILE}")
        print("ğŸ”§ Solution : Lance d'abord le notebook 01_nettoyage_capteurs.ipynb")
        return
    
    df_capteurs = pd.read_csv(CAPTEURS_FILE)
    print(f"âœ… Dataset chargÃ© : {len(df_capteurs):,} lignes")
    print()
    
    # Extraire stations uniques avec GPS + leurs dates
    print("ğŸ“ Extraction des stations et dates...")
    
    # Convertir dates
    df_capteurs['date'] = pd.to_datetime(df_capteurs['date'])
    
    # Grouper par station avec toutes leurs dates
    stations_with_dates = df_capteurs.groupby('station_id').agg({
        'latitude': 'first',
        'longitude': 'first',
        'date': lambda x: list(x.dt.strftime('%Y-%m-%d').unique())
    }).reset_index()
    
    stations_with_dates.columns = ['station_id', 'latitude', 'longitude', 'dates']
    
    if MAX_STATIONS:
        stations_with_dates = stations_with_dates.head(MAX_STATIONS)
        print(f"ğŸ”§ Mode test : {len(stations_with_dates)} stations")
    else:
        print(f"âœ… {len(stations_with_dates)} stations Ã  traiter")
    
    # Compter total de dates
    total_dates = sum(len(dates) for dates in stations_with_dates['dates'])
    print(f"ğŸ“… Total dates capteurs : {total_dates:,}")
    print(f"ï¿½ Moyenne : {total_dates/len(stations_with_dates):.1f} dates/station")
    print()
    
    # Charger checkpoint (stations dÃ©jÃ  traitÃ©es)
    completed_stations = load_checkpoint()
    if completed_stations:
        print(f"ğŸ”„ REPRISE DÃ‰TECTÃ‰E : {len(completed_stations)} stations dÃ©jÃ  tÃ©lÃ©chargÃ©es")
        print(f"ğŸ“Š Restant : {len(stations_with_dates) - len(completed_stations)} stations")
        print()
    
    # CrÃ©er dossier de sortie
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    os.makedirs(os.path.dirname(CHECKPOINT_FILE), exist_ok=True)
    
    # TÃ©lÃ©charger pour chaque station
    print("ğŸš€ DÃ©but du tÃ©lÃ©chargement...")
    print("=" * 70)
    
    success_count = 0
    error_count = 0
    skipped_count = 0
    total_images_count = 0
    is_first_save = not os.path.exists(OUTPUT_FILE)
    
    for idx, row in stations_with_dates.iterrows():
        station_id = row['station_id']
        
        # Skip si dÃ©jÃ  tÃ©lÃ©chargÃ©e
        if str(station_id) in completed_stations:
            skipped_count += 1
            if skipped_count % 10 == 0:  # Afficher tous les 10 skips
                print(f"â­ï¸  [{idx+1}/{len(stations_with_dates)}] {skipped_count} stations dÃ©jÃ  faites...")
            continue
        
        lat = row['latitude']
        lon = row['longitude']
        target_dates = row['dates']
        
        print(f"\n[{idx+1}/{len(stations_with_dates)}] Station {station_id} (lat={lat:.2f}, lon={lon:.2f})")
        print(f"  ğŸ“… {len(target_dates)} dates capteurs Ã  traiter")
        
        try:
            # TÃ©lÃ©charger satellites pour les dates capteurs uniquement
            df_station = extract_indices_for_dates(lat, lon, target_dates)
            
            if len(df_station) > 0:
                # Ajouter station_id
                df_station['station_id'] = station_id
                
                # RÃ©organiser colonnes
                df_station = df_station[['station_id', 'target_date', 'date', 'latitude', 'longitude',
                                        'NDWI', 'chlorophyll_index', 'turbidity_index', 
                                        'temperature_surface']].copy()
                df_station.rename(columns={'target_date': 'date_capteur', 'date': 'date_satellite'}, inplace=True)
                
                # Sauvegarder immÃ©diatement (progressive save)
                save_partial_results(df_station, is_first=is_first_save)
                is_first_save = False
                
                # Marquer comme terminÃ©e
                save_checkpoint(station_id)
                
                total_images_count += len(df_station)
                print(f"  âœ… {len(df_station)}/{len(target_dates)} images satellites trouvÃ©es et sauvegardÃ©es")
                success_count += 1
            else:
                print(f"  âš ï¸  Aucune image satellite disponible (nuages ou hors zone)")
                save_checkpoint(station_id)  # Marquer quand mÃªme pour skip
                error_count += 1
            
            # Pause pour Ã©viter rate limiting
            time.sleep(0.3)
            
        except Exception as e:
            print(f"  âŒ Erreur : {str(e)[:100]}")
            error_count += 1
            continue
    
    print()
    print("=" * 70)
    print("âœ… TÃ‰LÃ‰CHARGEMENT TERMINÃ‰ !")
    print()
    
    # Charger le fichier final pour stats
    if os.path.exists(OUTPUT_FILE):
        df_final = pd.read_csv(OUTPUT_FILE)
        
        print(f"ğŸ“Š STATISTIQUES :")
        print(f"  â€¢ Stations rÃ©ussies : {success_count}/{len(stations_with_dates)}")
        print(f"  â€¢ Stations Ã©chouÃ©es : {error_count}/{len(stations_with_dates)}")
        if skipped_count > 0:
            print(f"  â€¢ Stations skippÃ©es (dÃ©jÃ  faites) : {skipped_count}/{len(stations_with_dates)}")
        print(f"  â€¢ Total paires capteur-satellite : {len(df_final):,}")
        print(f"  â€¢ PÃ©riode capteurs : {df_final['date_capteur'].min()} â†’ {df_final['date_capteur'].max()}")
        print(f"  â€¢ PÃ©riode satellites : {df_final['date_satellite'].min()} â†’ {df_final['date_satellite'].max()}")
        print()
        print(f"ğŸ’¾ Fichier sauvegardÃ© : {OUTPUT_FILE}")
        print(f"ğŸ“ Taille : {len(df_final):,} lignes Ã— {len(df_final.columns)} colonnes")
        print()
        
        # AperÃ§u
        print("ğŸ“‹ APERÃ‡U DES DONNÃ‰ES :")
        print(df_final.head())
        print()
        
        # Nettoyer checkpoint si tout est fait
        if success_count + error_count + skipped_count >= len(stations_with_dates):
            if os.path.exists(CHECKPOINT_FILE):
                os.remove(CHECKPOINT_FILE)
                print("ğŸ§¹ Checkpoint nettoyÃ© (tÃ©lÃ©chargement complet)")
                print()
        
        print("ğŸ‰ Prochaine Ã©tape : Fusionner avec capteurs !")
        
    else:
        print("âŒ Aucune donnÃ©e rÃ©cupÃ©rÃ©e")
        print("ğŸ”§ VÃ©rifiez :")
        print("  - Connexion Earth Engine")
        print("  - CoordonnÃ©es GPS valides")
        print("  - PÃ©riode avec images disponibles")


if __name__ == '__main__':
    main()
