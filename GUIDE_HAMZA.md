# üéØ GUIDE HAMZA - STModel + Infrastructure
**Votre branche : `dev_hamza`**  
**Architecture : MICROSERVICES PROFESSIONNELLE**  
**Vos services : STModel (ML) + Infrastructure (Docker)**

---

## üèóÔ∏è ARCHITECTURE MICROSERVICES SIMPLE

### **üóÑÔ∏è VOTRE BASE DE DONN√âES D√âDI√âE** :
- **Nom** : `predictions_db` (PostgreSQL port 5434)
- **Tables** : 
  - `ml_models` ‚Üí Vos mod√®les ML (nom, version, pr√©cision)
  - `predictions` ‚Üí R√©sultats pr√©dictions (qualit√© eau, score, zone GPS)
  - `training_logs` ‚Üí Historique entra√Ænements
- **Avantage** : Vous seul y acc√©dez, vous pouvez modifier sans casser autres services

### **üì° APIS QUE VOUS APPELEZ** :

#### **De Bilal (Capteurs)** :
```
GET http://service_capteurs:8000/api/capteurs/data/latest
Vous recevez: {
  "capteurs": [
    {
      "capteur_id": "CAP001",
      "latitude": 33.5731,
      "longitude": -7.5898,
      "mesures": {
        "ph": 7.2,
        "temperature": 22.5,
        "turbidite": 12.3,
        "oxygene": 8.1
      },
      "timestamp": "2025-10-26T10:30:00Z"
    }
  ]
}
```

#### **De Bilal (Satellite)** :
```
GET http://service_satellite:8000/api/satellite/indices/latest
Vous recevez: {
  "indices": [
    {
      "image_id": "SAT001",
      "zone": {"latitude": 33.5731, "longitude": -7.5898, "rayon_km": 5},
      "indices": {
        "chlorophylle": 0.8,
        "turbidite_satellite": 15.2,
        "temperature_surface": 23.1
      },
      "timestamp": "2025-10-26T10:00:00Z"
    }
  ]
}
```

### **üìà MESSAGES QUE VOUS ENVOYEZ** :

#### **Vers Yassin (via Redis)** :
```
Canal: "new_prediction"
Vous envoyez: {
  "prediction_id": "PRED001",
  "zone": {"latitude": 33.5731, "longitude": -7.5898},
  "predictions": {
    "qualite_eau": "MAUVAISE",
    "score_qualite": 3.2,
    "ph_predit": 8.7,
    "risque_pollution": "ELEVE"
  },
  "confidence": 0.85,
  "timestamp": "2025-10-26T10:35:00Z"
}
```

### **üìä API QUE VOUS POUVEZ CR√âER** :

#### **Service STModel** :
```
GET /api/predictions/latest
Vous retournez: {
  "predictions": [
    {
      "prediction_id": "PRED001",
      "model_name": "water_quality_v1",
      "zone": {"latitude": 33.5731, "longitude": -7.5898},
      "predictions": {
        "qualite_eau": "MAUVAISE",
        "score_qualite": 3.2,
        "ph_predit": 8.7,
        "risque_pollution": "ELEVE"
      },
      "confidence": 0.85,
      "timestamp": "2025-10-26T10:35:00Z"
    }
  ]
}

POST /api/predictions/create
Vous recevez: zone_GPS
Vous retournez: nouvelle pr√©diction
```

**üéØ VOTRE R√îLE : Recevoir donn√©es ‚Üí Faire pr√©dictions ML ‚Üí Envoyer r√©sultats**

---

## ÔøΩüìã CE QUE VOUS FAITES

### üß† **Service STModel** 
- API pour pr√©dictions qualit√© eau (Python + FastAPI)
- Mod√®les machine learning pour pr√©dire les donn√©es
- Port : 8003

### üîß **Infrastructure**
- Gestion Docker et base de donn√©es
- Configuration g√©n√©rale du projet

---

## ÔøΩ WORKFLOW QUOTIDIEN SIMPLE

### **1. D√©marrer votre travail**
```powershell
# 1. Aller dans le projet
cd "C:\Users\Hamza\Documents\EMSI 5\ML+DM+MicroServices\aquawatch-ms"

# 2. Basculer sur votre branche
git checkout dev_hamza

# 3. R√©cup√©rer les derni√®res modifications
git pull origin development

# 4. D√©marrer Docker Desktop (attendre qu'il soit vert)

# 5. D√©marrer TOUTES les bases microservices
docker compose up db_capteurs db_satellite db_predictions db_alerts db_geo redis_queue minio_storage -d
```

### **2. D√©velopper votre service**
```powershell
# Tester votre service STModel
docker compose up service_stmodel
```

**üìù Votre code va dans : `services/service_stmodel/src/`**

### **3. Sauvegarder votre travail**
```powershell
# 1. Voir ce que vous avez modifi√©
git status

# 2. Ajouter vos modifications
git add .

# 3. Sauvegarder avec un message
git commit -m "feat: [ce que vous avez fait]"

# 4. Envoyer sur GitHub
git push origin dev_hamza
```

---

## ÔøΩ PROCESSUS √âTAPE PAR √âTAPE - VOS T√ÇCHES

### **üìã FLUX SERVICE STMODEL** :

#### **√âtape 1 - Connecter √† PostgreSQL**
- **Outil** : `psycopg2` (Python PostgreSQL driver)
- **Action** : Connexion √† VOTRE base `predictions_db` port 5434
- **Variables** : `DATABASE_URL=postgresql://predictions_user:predictions_pass_2025@db_predictions:5432/predictions_db`

#### **√âtape 2 - Configurer PyTorch**
- **Outil** : `torch` + `torchvision` + `pytorch-lightning`
- **Action** : Initialiser mod√®les ConvLSTM pour pr√©dictions spatio-temporelles
- **GPU** : D√©tecter CUDA si disponible, sinon CPU

#### **√âtape 3 - R√©cup√©rer donn√©es de Bilal**
- **Outil** : `requests` Python HTTP client
- **Action** : Appels APIs capteurs et satellite de Bilal
- **URLs** : `http://service_capteurs:8000/api/capteurs/data/latest` et `http://service_satellite:8000/api/satellite/indices/latest`

#### **√âtape 4 - Pr√©parer donn√©es ML**
- **Outil** : `pandas` + `numpy` pour preprocessing
- **Action** : Normaliser donn√©es, cr√©er s√©quences temporelles pour ConvLSTM
- **Features** : Combiner capteurs IoT + indices satellites + coordonn√©es GPS

#### **√âtape 5 - Faire pr√©dictions**
- **Outil** : Mod√®les PyTorch ConvLSTM entra√Æn√©s
- **Action** : Pr√©dire qualit√© eau √† 24h/72h avec scores de confiance
- **Output** : Score qualit√© (0-10), cat√©gorie (BONNE/MOYENNE/MAUVAISE), risque pollution

#### **√âtape 6 - Stocker pr√©dictions**
- **Outil** : PostgreSQL `INSERT` dans table `predictions`
- **Action** : Sauver r√©sultats avec timestamp, zone GPS, model_id
- **Index** : Optimiser requ√™tes par zone et temps

#### **√âtape 7 - Publier vers Yassin**
- **Outil** : `redis` Python client
- **Action** : Publier message sur canal "new_prediction"
- **Format** : JSON avec pr√©dictions + zone GPS pour d√©clenchement alertes

#### **√âtape 8 - Exposer API ML**
- **Outil** : FastAPI routes Python
- **Action** : Endpoint `/api/predictions/latest` pour consultation pr√©dictions
- **Authentification** : Basic auth si n√©cessaire

### **üìã FLUX INFRASTRUCTURE DOCKER** :

#### **√âtape 1 - G√©rer docker-compose.yml**
- **Outil** : Docker Compose orchestration
- **Action** : Maintenir configuration 8 services + bases d√©di√©es
- **Dependencies** : Ordre d√©marrage correct (bases ‚Üí services)

#### **√âtape 2 - Variables d'environnement**
- **Outil** : Fichier `.env` centralis√©
- **Action** : G√©rer credentials bases, ports, cl√©s API
- **S√©curit√©** : Passwords forts, s√©paration dev/prod

#### **√âtape 3 - Monitoring infrastructure**
- **Outil** : `docker compose ps` + `docker stats`
- **Action** : V√©rifier sant√© services, usage ressources
- **Logs** : Centraliser avec `docker compose logs`

---

## ÔøΩüìã VOS T√ÇCHES D√âTAILL√âES

### **üéØ Service STModel - Pr√©dictions Spatio-Temporelles**

**Votre dossier :** `services/service_stmodel/src/`

#### **Phase 1 - API de base avec PyTorch** 
```python
# Cr√©er src/index.py - Point d'entr√©e FastAPI
from fastapi import FastAPI
import torch
import torch.nn as nn

app = FastAPI()

@app.get("/health")
def health():
    return {"status": "ok", "service": "stmodel", "pytorch": torch.__version__}

@app.get("/predict")  
def predict():
    return {"prediction": "ConvLSTM ready", "model_type": "spatio-temporal"}
```

#### **Phase 2 - Connexion donn√©es** 
- **VOTRE base** : Connecter √† `predictions_db` PostgreSQL
- **APIs √† appeler** : 
  - `GET service_capteurs:8000/api/capteurs/data/latest` ‚Üí Donn√©es capteurs
  - `GET service_satellite:8000/api/satellite/indices/latest` ‚Üí Indices satellite
- **Outils** : Python, PostgreSQL adapter, HTTP client (requests/httpx)

#### **Phase 3 - Mod√®les ConvLSTM + Communication**
- **PyTorch ConvLSTM** : Mod√®les spatio-temporels pour pr√©dictions qualit√© eau
- **PyTorch Lightning** : Framework pour entra√Ænement optimis√© mod√®les complexes
- **Stockage** : Sauver pr√©dictions dans VOTRE base `predictions_db`
- **Communication** : Publier sur canal Redis `"new_prediction"` ‚Üí Vers Yassin
- **API** : `GET /api/predictions/latest` avec pr√©dictions 24h/72h
- **Outils** : PyTorch, ConvLSTM, Pandas, Redis client

#### **Phase 4 - Mod√®les professionnels** 
- **R√©seaux spatio-temporels** : ConvLSTM pour s√©ries temporelles g√©olocalis√©es
- **Pr√©dictions multiples** : 24h/72h avec intervalles de confiance
- **Fusion donn√©es** : Capteurs + Satellites + M√©t√©o pour pr√©cision maximale

**üõ†Ô∏è OUTILS √Ä UTILISER :**
- **FastAPI** ‚Üí APIs web
- **PostgreSQL** ‚Üí VOTRE base `predictions_db` (port 5434)
- **PyTorch + ConvLSTM** ‚Üí Mod√®les spatio-temporels professionnels
- **PyTorch Lightning** ‚Üí Framework ML avanc√© pour entra√Ænement
- **Requests/HTTPx** ‚Üí Appeler APIs de Bilal
- **Redis** ‚Üí Envoyer messages √† Yassin
- **Pandas + Scikit-learn** ‚Üí Pr√©paration donn√©es ML
- **Docker** ‚Üí Votre service en container

---

## üîó INT√âGRATION SIMPLE

### **APIs √† cr√©er pour envoyer vos pr√©dictions** :
```python
# Dans src/index.py
@app.get("/api/predictions/latest")
def get_latest_predictions():
    return {
        "prediction_id": "PRED001",
        "qualite_eau": "BONNE",  # BONNE, MOYENNE, MAUVAISE
        "score_qualite": 7.2,    # 0-10
        "risque_pollution": "FAIBLE"  # FAIBLE, MOYEN, ELEVE
    }
```

### **APIs √† appeler pour r√©cup√©rer les donn√©es** :
```python
# Donn√©es capteurs de Bilal
GET http://service_capteurs:8001/api/capteurs/derniere

# Donn√©es satellite de Bilal  
GET http://service_satellite:8002/api/satellite/indices
```

**‚ö° R√àGLE SIMPLE : M√™me format JSON partout = int√©gration facile !**

---

## üÜò SI VOUS AVEZ UN PROBL√àME

### **Le service ne d√©marre pas**
```powershell
# Voir l'erreur
docker compose logs service_stmodel

# Reconstruire
docker compose build service_stmodel
docker compose up service_stmodel
```

### **VOTRE base d√©di√©e ne marche pas**
```powershell
# V√©rifier VOTRE base predictions_db
docker compose logs db_predictions

# Se connecter √† VOTRE base
docker exec -it aquawatch-ms-db_predictions-1 psql -U predictions_user -d predictions_db

# Red√©marrer si n√©cessaire
docker compose restart db_predictions
```

### **Git ne marche pas**
```powershell
# Voir l'√©tat
git status

# Si conflit
git pull origin development
# R√©soudre conflits manuellement
git add .
git commit -m "fix: r√©solution conflits"
```

---

**üí° Commencez par une API simple qui retourne "Hello World", puis ajoutez les fonctionnalit√©s une par une !**